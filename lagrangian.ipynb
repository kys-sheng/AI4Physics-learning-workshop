{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369682e",
   "metadata": {},
   "source": [
    "# ðŸŽ“ Part 2: \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaae72",
   "metadata": {},
   "source": [
    "# <u>**Learning outcomes**</u> :  Considerations needed in each step of a project!\n",
    "- Essentially, in each step of your project, things to consider\n",
    "- In reality, what will be relevant are heavily dependent on your project in mind!\n",
    "- we will use a mixture of mathematics example and example from Lagrangian task\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e25c63",
   "metadata": {},
   "source": [
    "# <u>Content</u>:\n",
    "<h4>\n",
    "1. Datasets : Distributions and Tokenization <br>\n",
    "2. Training : Where to find resources!<br>\n",
    "3. Evaluations : Metric vs Score, Embedding Analysis, Oout-Of-Domain Generalization<br>\n",
    "</h4>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade93c0",
   "metadata": {},
   "source": [
    "Before anything else, load some basic libraries :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf0dcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4dc9c",
   "metadata": {},
   "source": [
    "# 1. **Preparing your Dataset**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eccef88",
   "metadata": {},
   "source": [
    "## **Rule of Thumb** : NN are good interpolators, but not that good of an extrapolator.\n",
    "- NN learns from data.\n",
    "- If the model is asked on something it has never seen, it figure outs based on existing experience \n",
    "- Training Data Distribution matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3ae47",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836574f",
   "metadata": {},
   "source": [
    "# **1a. Data Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972275e",
   "metadata": {},
   "source": [
    "## **Where to start?**  Think of your use case, and go from there!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a605ef",
   "metadata": {},
   "source": [
    "## Example in Math (from Part 1) :\n",
    "<div align=\"center\">\n",
    "     <h2> x + y => ? </h2>\n",
    "</div>\n",
    "\n",
    "## Use case : add any two numbers independent of the number's digits, <br> be it between 1-digit numbers (2+2) or 5-digit numbers (20000+16378)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3b9d",
   "metadata": {},
   "source": [
    "\n",
    "Let's generate numbers from 1-10000 and do addition as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36f0771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 10000\n",
    "min_num      = 1\n",
    "max_num      = 10000\n",
    "\n",
    "# Generate random examples\n",
    "examples     = [(random.randint(min_num, max_num),random.randint(min_num, max_num)) for _ in range(num_examples)]\n",
    "df           = pd.DataFrame(examples, columns=['x', 'y'])\n",
    "df['sum']    = df['x'] + df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc760cc6",
   "metadata": {},
   "source": [
    "Lets check the number of digits in each number in our dataset. So,  <br>\n",
    "- <u>7</u> = 1 digit\n",
    "- <u>42</u> = 2 digits\n",
    "- <u>999</u> = 3 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8839a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets compute the number of digits in each number\n",
    "df['x_digit'] = df['x'].apply(lambda x: len(str(x)))    \n",
    "df['y_digit'] = df['y'].apply(lambda x: len(str(x)))    \n",
    "df['sum_digit'] = df['sum'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Plot the distribution of number of digits\n",
    "df['x_digit'].hist(label=\"x\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['y_digit'].hist(label=\"y\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['sum_digit'].hist(label=\"sum\",range=(1,6),bins=5,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of number of digits\")\n",
    "plt.xlabel(\"Number of digits\")  \n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f96d97",
   "metadata": {},
   "source": [
    "### Probability of the model to learn the addition with the **both number** having 1 digit, 2 digits, 3 digits, 4 digits, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b10943d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(both_digit=1) =  0.0\n",
      "P(both_digit=2) =  0.0\n",
      "P(both_digit=3) =  0.7799999999999999\n",
      "P(both_digit=4) =  80.15\n",
      "P(both_digit=5) =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"P(both_digit=1) = \", len(df[(df[\"x_digit\"] == 1) & (df[\"y_digit\"] == 1)]) / num_examples * 100)\n",
    "print(\"P(both_digit=2) = \", len(df[(df[\"x_digit\"] == 2) & (df[\"y_digit\"] == 2)]) / num_examples * 100)\n",
    "print(\"P(both_digit=3) = \", len(df[(df[\"x_digit\"] == 3) & (df[\"y_digit\"] == 3)]) / num_examples * 100)\n",
    "print(\"P(both_digit=4) = \", len(df[(df[\"x_digit\"] == 4) & (df[\"y_digit\"] == 4)]) / num_examples * 100)\n",
    "print(\"P(both_digit=5) = \", len(df[(df[\"x_digit\"] == 5) & (df[\"y_digit\"] == 5)]) / num_examples * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07424",
   "metadata": {},
   "source": [
    "### Probability of the model to learn additions that leads to a sum with 1 digit, 2 digits, 3 digits, 4 digits, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1498d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(sum_digit=1) =  0.0\n",
      "P(sum_digit=2) =  0.0\n",
      "P(sum_digit=3) =  0.53\n",
      "P(sum_digit=4) =  49.66\n",
      "P(sum_digit=5) =  49.81\n"
     ]
    }
   ],
   "source": [
    "print(\"P(sum_digit=1) = \", len(df[df[\"sum_digit\"] == 1]) / num_examples* 100)\n",
    "print(\"P(sum_digit=2) = \", len(df[df[\"sum_digit\"] == 2]) / num_examples* 100)\n",
    "print(\"P(sum_digit=3) = \", len(df[df[\"sum_digit\"] == 3]) / num_examples* 100)\n",
    "print(\"P(sum_digit=4) = \", len(df[df[\"sum_digit\"] == 4]) / num_examples* 100)\n",
    "print(\"P(sum_digit=5) = \", len(df[df[\"sum_digit\"] == 5]) / num_examples* 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82add299",
   "metadata": {},
   "source": [
    "What you should do is actual oversample the existing cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d9ba9",
   "metadata": {},
   "source": [
    "Reference : https://arxiv.org/pdf/2308.15594 (Data Distribution affects GCD usecase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2eeb50",
   "metadata": {},
   "source": [
    "## Example in Lagrangian example [Skip]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c685ae6",
   "metadata": {},
   "source": [
    "### Model Task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685f416",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/dGfUOPB.png\" alt=\"Distribtuion\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f97dcc",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/abs/2501.09729\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4b481",
   "metadata": {},
   "source": [
    "### Use Case : <br> A. Want to work with different number of fields <br> B. Want work with varying interactions <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc59d80",
   "metadata": {},
   "source": [
    "We generated two datasets to look into this: \n",
    "- One with more trilinears (harder to get if randomly sample) but less large number of fields\n",
    "- One randomly sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba04bac",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/K7p8fLR.png\" alt=\"Distribtuion\" width=\"500\">\n",
    "    <p><em>Figure 1: Sampled Distribution.</em></p>\n",
    "    <img src=\"https://i.imgur.com/s4MJA9v.png\" alt=\"Distribtuion\" width=\"500\">\n",
    "    <p><em>Figure 2: Uniform Distribution.</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598fd17",
   "metadata": {},
   "source": [
    "### Results by nfields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75489387",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/CydNCo8.png\" alt=\"Distribtuion\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a442f",
   "metadata": {},
   "source": [
    "Reference : Train set priming https://arxiv.org/abs/2306.15400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc126825",
   "metadata": {},
   "source": [
    "### Results by trilinears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd488d",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/tK2izbI.png\" alt=\"Distribtuion\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c7aa2",
   "metadata": {},
   "source": [
    "# TAKEAWAY: What's your use case and build your data around that!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032383a",
   "metadata": {},
   "source": [
    "# **1b. Tokenization choices**\n",
    "## Considerations: \n",
    "- What information is required for your model to learn?\n",
    "- Do you care about expressivity? \n",
    "- Do you care about Out-of-Distribution scenarios?\n",
    "\n",
    "## Practical \n",
    "- How much information?\n",
    "- Vocabulary Size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1250b",
   "metadata": {},
   "source": [
    "### Choices of Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0833bf0",
   "metadata": {},
   "source": [
    "In Language:\n",
    "Example Phrase : AI For Physics\n",
    "- Word-Level : AI, For, Physics\n",
    "- Character-Level : A, I,  , F, o, r,  , P, h, y, s, i, c, s\n",
    "\n",
    "In Math:\n",
    "Example Expression : 100 + 420 = 520\n",
    "- \"Term\"-level : 100, +, 420, =, 520\n",
    "- \"Digit\"-Level : 1, 0, 0,  +,  4, 2, 0, =,  5, 2, 0\n",
    "\n",
    "In Lagrangians:\n",
    "Example Field : Higgs Particle\n",
    "- Symbol Level : H\n",
    "- Quantum-Numbers-Level: FIELD, SPIN, 0, SU2, 2, U1, 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddda171",
   "metadata": {},
   "source": [
    "Remark: \n",
    "1. Detailed tokenization : \n",
    "- less vocabulary\n",
    "- more expressive\n",
    "- more token per sequence\n",
    "- heavy on attention mechanism\n",
    "2. Coarse tokenization : \n",
    "- more vocabulary\n",
    "- less expressive\n",
    "- less token per sequence\n",
    "- easier on attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88417b",
   "metadata": {},
   "source": [
    "### Example : Math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4674bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# Character-level \n",
    "# 1. Generate arithmetic corpus\n",
    "char_level_corpus = [\" \".join(list(f\"{a}+{b}={str(a + b)}\")) for a in range(1000) for b in range(1000)]\n",
    "vocab = {\"1\" : 1, \"2\" : 2, \"3\" : 3, \"4\" : 4, \"5\" : 5, \"6\" : 6, \"7\" : 7, \"8\" : 8, \"9\" : 9,\n",
    "         \"0\" : 0, \"+\" : 10, \"=\" : 11,\"[UNK]\" : 12, \"[PAD]\" : 13, \"[BOS]\" : 14, \"[EOS]\" : 15}\n",
    "# 2. Initialize tokenizer components\n",
    "char_level_tokenizer = Tokenizer(WordLevel(vocab=vocab, unk_token=\"[UNK]\"))\n",
    "char_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "\n",
    "# Word-level \n",
    "word_level_corpus = [f\"{a} + {b} = {str(a + b)}\" for a in range(1000) for b in range(1000)]\n",
    "word_level_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "word_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    "trainer = WordLevelTrainer(special_tokens=special_tokens)\n",
    "word_level_tokenizer.train_from_iterator(word_level_corpus, trainer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7084ce",
   "metadata": {},
   "source": [
    "lets see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c3bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_example :  8 5 5 + 6 7 5 = 1 5 3 0\n",
      "char_level_tokens  :  ['8', '5', '5', '+', '6', '7', '5', '=', '1', '5', '3', '0']\n",
      "char_level_Ntokens :  12\n",
      "\n",
      "word_level_example :  439 + 390 = 829\n",
      "word_level_tokens  :  ['439', '+', '390', '=', '829']\n",
      "word_level_Ntokens :  5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_level_example = random.choice(char_level_corpus)\n",
    "print(\"char_level_example : \",char_level_example)\n",
    "print(\"char_level_tokens  : \",char_level_tokenizer.encode(char_level_example).tokens)\n",
    "print(\"char_level_Ntokens : \",len(char_level_tokenizer.encode(char_level_example).tokens),end=\"\\n\\n\")\n",
    "\n",
    "word_level_example = random.choice(word_level_corpus)\n",
    "print(\"word_level_example : \",word_level_example)\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(word_level_example).tokens)\n",
    "print(\"word_level_Ntokens : \",len(word_level_tokenizer.encode(word_level_example).tokens),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0e18c",
   "metadata": {},
   "source": [
    "Lets check vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a761b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_vocab_size:  16\n",
      "word_level_vocab_size:  2005\n"
     ]
    }
   ],
   "source": [
    "print(\"char_level_vocab_size: \",char_level_tokenizer.get_vocab_size())\n",
    "print(\"word_level_vocab_size: \",word_level_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e264e",
   "metadata": {},
   "source": [
    "Try encoding 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f466c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_tokens  :  ['1', '0', '0', '0', '0']\n",
      "\n",
      "word_level_tokens  :  ['[UNK]']\n",
      "\n",
      "word_level_tokens  :  ['10', '0', '0', '0']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OOD_char_level_example =   \"1 0 0 0 0\"\n",
    "print(\"char_level_tokens  : \",char_level_tokenizer.encode(OOD_char_level_example).tokens,end=\"\\n\\n\")\n",
    "\n",
    "OOD_word_level_example =   \"10000\"\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(OOD_word_level_example).tokens,end=\"\\n\\n\")\n",
    "\n",
    "# Something like this is possible but not intuitive (words and number are slightly different)\n",
    "OOD_word_level_example =   \"10 0 0 0\"\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(OOD_word_level_example).tokens,end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad87274",
   "metadata": {},
   "source": [
    "### Example : Fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f1e9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  FIELD SPIN 0 SU2 3 FIELD SPIN 1/2 SU2 2 U1 8 / 9 HEL -1/2 FIELD SPIN 0 SU3 - 3 SU2 3 U1 1 / 9\n",
      "token_id =  [22, 36, 9, 37, 10, 22, 36, 5, 4, 6, 37, 6, 39, 15, 4, 16, 23, 7, 5, 4, 6, 22, 36, 9, 38, 7, 10, 37, 10, 39, 5, 4, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:39:24.072660: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-10 03:39:24.310591: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-10 03:39:25.620747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded  =  FIELD SPIN 0 SU2 3 FIELD SPIN 1 / 2 SU2 2 U1 8 / 9 HEL - 1 / 2 FIELD SPIN 0 SU3 - 3 SU2 3 U1 1 / 9\n"
     ]
    }
   ],
   "source": [
    "from transformers import  PreTrainedTokenizerFast\n",
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"JoseEliel/BART-Lagrangian\")\n",
    "sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "\n",
    "example = sampled_df.sample(1)[\"fields\"].values[0]\n",
    "print(\"Input    = \",example)\n",
    "encoded = hf_tokenizer.encode(example)\n",
    "print(\"token_id = \", encoded)\n",
    "decoded = hf_tokenizer.decode(encoded)\n",
    "print(\"decoded  = \", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5865a",
   "metadata": {},
   "source": [
    "#### TAKEAWAY : THe level of tokenization affects attention usage and vocab size \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f152260",
   "metadata": {},
   "source": [
    "# Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5a3b8",
   "metadata": {},
   "source": [
    "### NAISS : https://www.naiss.se/\n",
    "- Provider of compute and storage resources\n",
    "- For any researchers based in Sweden\n",
    "### SUPR : https://supr.naiss.se/\n",
    "- Portal to apply for it. \n",
    "- There are varyind levels of applications [small, medium, large]\n",
    "- PhD students and above can already apply for small compute (Alvis: 1000GPUhs/months and Dardel: 20000 CPU-h/month!)\n",
    "\n",
    "### Alvis : https://www.c3se.chalmers.se/about/Alvis/ <br> OnDemand Portal : https://alvis.c3se.chalmers.se/pun/sys/dashboard/\n",
    "\n",
    "### Dardel : https://www.pdc.kth.se/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926aecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9823e0",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "- Generating output from the model.\n",
    "- Discussion on evaluation choices:\n",
    "  - Existing or novel metrics.\n",
    "  - Embedding analysis.\n",
    "  - Out-of-distribution tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b2ab6",
   "metadata": {},
   "source": [
    "## Existing Metric  : Does it work? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c788b83",
   "metadata": {},
   "source": [
    "mainly to see if things work as expected\n",
    "Loss : Deviation from actual term \n",
    "Accuracy : How much is perfect? \n",
    "New metric, Score : (Order does not always matter, XEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU if available\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name = \"JoseEliel/BART-Lagrangian\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "#hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d150b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data if not already loaded, drop duplicates\n",
    "#sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "sampled_df.drop_duplicates(subset=[\"fields\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1b2fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5498f",
   "metadata": {},
   "source": [
    "### Example : Lagrangian Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b01da",
   "metadata": {},
   "source": [
    "Choose a random lagrangian to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18376d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_scenario = sampled_df.sample(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709e360",
   "metadata": {},
   "source": [
    "Look at the input (field content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c89747",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example_scenario[\"fields\"].values[0]\n",
    "example_input = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc9f9",
   "metadata": {},
   "source": [
    "Look at the output (Lagrangian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecab14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = example_scenario[\"Lagrangian\"].values[0]\n",
    "example_output = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Output   = \",example_output)\n",
    "encoded_output = hf_tokenizer.encode(example_output)\n",
    "print(\"token_id = \", encoded_output)\n",
    "decoded_output = hf_tokenizer.decode(encoded_output)\n",
    "print(\"decoded  = \", decoded_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8dc620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the terms \n",
    "separated_terms = le.sep_terms(decoded_output)\n",
    "\n",
    "print(\"First five terms: \")\n",
    "for i in range(5):\n",
    "    print(f\"term {i} : \",\" \".join(separated_terms[i]))\n",
    "lag_truth_1 =  \" \".join([\" \".join(i) for i in separated_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd382b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the first and second terms using list \n",
    "separated_terms[0],separated_terms[1] = separated_terms[1],separated_terms[0]\n",
    "\n",
    "print(\"First five terms after reordering: \")\n",
    "for i in range(5):\n",
    "    print(f\"term {i} : \",\" \".join(separated_terms[i]))\n",
    "\n",
    "lag_truth_2 =  \" \".join([\" \".join(i) for i in separated_terms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4582290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lag_truth_1 : \",lag_truth_1)\n",
    "print(\"lag_truth_2 : \",lag_truth_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inputs:\\n\", encoded_input)\n",
    "print()\n",
    "\n",
    "print(\"Outputs:\",)\n",
    "targets_1 = hf_tokenizer(\"[SOS] \" + lag_truth_1 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True)\n",
    "targets_2 = hf_tokenizer(\"[SOS] \" + lag_truth_2 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "#print(\"targets_1: \", targets_1)\n",
    "labels_1 = targets_1[\"input_ids\"]\n",
    "#print(\"targets_2: \", targets_2)\n",
    "labels_2 = targets_2[\"input_ids\"]\n",
    "\n",
    "\n",
    "#print(\"inputs: \", hf_tokenizer.decode(encoded_input))\n",
    "print(\"labels_1: \", labels_1)\n",
    "#print(\"labels_1: \", hf_tokenizer.decode(labels_1[0]))\n",
    "print(\"labels_2: \", labels_2)\n",
    "#print(\"labels_2: \", hf_tokenizer.decode(labels_2[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffd64d",
   "metadata": {},
   "source": [
    "Generate the Lagrangians and calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07006038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # loss with labels_1 and labels_2\n",
    "    outputs_1 = model(input_ids=torch.tensor(encoded_input).unsqueeze(0), labels=labels_1)\n",
    "    print(\"loss with labels_1:\", outputs_1.loss)\n",
    "    \n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_1 = torch.argmax(outputs_1.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_1 = hf_tokenizer.decode(predicted_token_ids_1[0], skip_special_tokens=True)\n",
    "    \n",
    "    outputs_2 = model(input_ids=torch.tensor(encoded_input).unsqueeze(0), labels=labels_2)\n",
    "    print(\"loss with labels_2:\", outputs_2.loss)\n",
    "\n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_2 = torch.argmax(outputs_2.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_2 = hf_tokenizer.decode(predicted_token_ids_2[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get the prediction during inference\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0), max_length=len(labels_1[0]))\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c437825",
   "metadata": {},
   "source": [
    "### TAKEAWAY : LOSS IS NOT ORDER/PERMUTATION INVARIANT!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e3634",
   "metadata": {},
   "source": [
    "Calculate the score :\n",
    "\n",
    "<div align=\"center\">\n",
    "     <h2> S_Lagrangian = S_contraction - P_length </h2>\n",
    "</div>\n",
    "\n",
    "where:\n",
    "- S_contraction = N_correct / N_true\n",
    "- P_length      = N_Extra / N_true     \n",
    "- S_object      = N_correct_objects / N_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf03ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "lscore_1, obscore_1, conscore_1, lpen_1 = le.get_lagrangian_score(predicted_string,lag_truth_1)\n",
    "lscore_2, obscore_2, conscore_2, lpen_2 = le.get_lagrangian_score(predicted_string,lag_truth_2)\n",
    "\n",
    "print(\"Prediction        : \", predicted_string)\n",
    "print()\n",
    "print(\"Truth_1           : \", lag_truth_1)\n",
    "print(\"Lagrangian score  : \",lscore_1)\n",
    "print(\"Object score      : \",obscore_1)\n",
    "print(\"Contraction Score : \",conscore_1)\n",
    "print(\"Length penalty    : \",lpen_1)\n",
    "print()\n",
    "print(\"Truth_2           : \", lag_truth_2)\n",
    "print(\"Lagrangian score  : \",lscore_2)\n",
    "print(\"Object score      : \",obscore_2)\n",
    "print(\"Contraction Score : \",conscore_2)\n",
    "print(\"Length penalty    : \",lpen_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bb943",
   "metadata": {},
   "source": [
    "## Why we need model.generate() instead of model() [Skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8403f48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p1,p2,t1,t2,p in zip(le.split_terms(predicted_string_1),le.split_terms(predicted_string_2), le.split_terms(lag_truth_1), le.split_terms(lag_truth_2),le.split_terms(predicted_string)):\n",
    "    print(\"Predicted_1 : \",p1)\n",
    "    print(\"Truth_1     : \",t1)\n",
    "    print(\"--\")\n",
    "    print(\"Predicted_2 : \",p2)\n",
    "    print(\"Truth_2     : \",t2)\n",
    "    print(\"--\")\n",
    "    print(\"Predicted   : \",p)\n",
    "    print(\"-----\")\n",
    "    print()\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf97e2",
   "metadata": {},
   "source": [
    "## Embedding analysis : What has it really learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72478e40",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is efficiency the only think you need? \n",
    "- Or is it important for you to know whether the model knows what it is learning? \n",
    "\n",
    "Practical Questions : \n",
    "- Can it associate inputs to some embedding space? <br> \n",
    "- Can it understand relations between inputs?  <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7a58d",
   "metadata": {},
   "source": [
    "### What is embedding analysis? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed3dde",
   "metadata": {},
   "source": [
    "Basically information encoded in a learned vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041fe80",
   "metadata": {},
   "source": [
    "<h4> Example in English-German translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60130ae",
   "metadata": {},
   "source": [
    "![Embeddings in LLM](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*52X2L01wpUjy39lIjofC7g.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3bd51",
   "metadata": {},
   "source": [
    "<h4> Example of food words embeddings and their corresponding possible axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb71eb",
   "metadata": {},
   "source": [
    "![Embeddings in LLM](https://developers.google.com/static/machine-learning/crash-course/images/embeddings_3D_tangyuan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de8251",
   "metadata": {},
   "source": [
    "### Example : Embeddings of different field symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfb9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"nfields\"] = sampled_df[\"fields\"].apply(lambda x: x.count(\"FIELD\"))\n",
    "sampled_1f_scenarios_df = sampled_df[sampled_df[\"nfields\"]==1]\n",
    "sampled_1f_scenarios_df = sampled_1f_scenarios_df.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf514d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields      = sampled_1f_scenarios_df[\"fields\"].apply(lambda x: set([\"FIELD \"+k for k in x.split(\"FIELD \") if k != \"\"])).to_list()\n",
    "uniq_fields_list_1f = list(set.union(*(fields)))\n",
    "uniq_fields_list_1f = [str((\"[SOS] \"+ k + \" [EOS]\").replace(\"  \",\" \")) for k in uniq_fields_list_1f]\n",
    "uniq_fields_list_1f = np.unique(uniq_fields_list_1f).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4d73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the first 10 unique fields\n",
    "for i in uniq_fields_list_1f[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef2e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "inputs_batch = hf_tokenizer(uniq_fields_list_1f, return_tensors='pt', truncation=True,padding=True).to(device)\n",
    "data_loader  = DataLoader( torch.tensor(inputs_batch[\"input_ids\"]).to(device), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Example of getting embeddings of specific cases\n",
    "\n",
    "all_embedding_1f = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for xinput in tqdm(data_loader):\n",
    "        outputs = model(xinput.to(device), output_hidden_states=True)\n",
    "        # Get the embeddings, which we choose to be the encoder's last hidden state of the first token\n",
    "        embeddings_enc = outputs.encoder_last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embedding_1f.append( torch.tensor(embeddings_enc))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185713fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedding_1f = torch.cat(all_embedding_1f, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef20ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedding_1f.shape # (100, 1024) = 100 samples, 1024 dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3)\n",
    "tsne_results = tsne.fit_transform(all_embedding_1f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb9b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_3d_tsne(tsne_results, clusters_dat, with_noise=True,elev=30, azim=30,info_dict=None,cluster_order=None,title=\"3D Clusters of BART\"):\n",
    "    \"\"\"\n",
    "    Plots a 3D scatter plot of t-SNE results\n",
    "    \n",
    "    Parameters:\n",
    "    - tsne_results (numpy.ndarray): The 3D coordinates from t-SNE, shape (n_samples, 3).\n",
    "    - clusters_dat (numpy.ndarray): The cluster labels from DBSCAN, shape (n_samples,).\n",
    "    - elev (float): Elevation angle for the 3D plot.\n",
    "    - azim (float): Azimuthal angle for the 3D plot.\n",
    "    \"\"\"\n",
    "    if cluster_order is None: cluster_order = np.unique(clusters_dat)\n",
    "\n",
    "    colors = plt.colormaps['tab20']\n",
    "    \n",
    "    if info_dict is not None: cluster_colors = {cluster: colors(i) for i, cluster in enumerate(info_dict.keys())}\n",
    "    else                    : cluster_colors = {cluster: colors(i) for i, cluster in enumerate(cluster_order)}\n",
    "\n",
    "    # Create an interactive 3D scatter plot\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    for cluster in cluster_order:\n",
    "        if not with_noise and cluster == -1: continue\n",
    "        cluster_points = tsne_results[np.array(clusters_dat) == cluster]\n",
    "        if info_dict is None:\n",
    "            cluster_label=f'Cluster {cluster}'\n",
    "        else:\n",
    "            try    :cluster_label=f'{info_dict[cluster][\"tag\"]}'\n",
    "            except :cluster_label=f'{info_dict[cluster]}'\n",
    "\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], \n",
    "                       color=cluster_colors[cluster], label=cluster_label, alpha=0.7)\n",
    "\n",
    "    \n",
    "    ax.legend(loc='lower right', fontsize=\"medium\", bbox_to_anchor=(.35, .65))\n",
    "\n",
    "    # Setting labels and title\n",
    "    ax.set_xlabel('TSNE Component 1',fontsize=\"medium\")\n",
    "    ax.set_ylabel('TSNE Component 2',fontsize=\"medium\")\n",
    "    ax.set_zlabel('TSNE Component 3',fontsize=\"medium\")\n",
    "    ax.tick_params(labelsize=\"small\")    # Use ax.set_title() for a 3D plot and adjust the padding\n",
    "    # Use fig.suptitle instead of ax.set_title for better control\n",
    "    fig.suptitle(title, fontsize=\"large\")  # y controls the vertical position; lower values move it closer to the plot\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)  # You can further lower the top value to move the plot down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case it takes forever, load the tsne reduced embedding vectors\n",
    "# with open(\"./tsne_results.pkl\", 'rb') as f:    tsne_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c65e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(sampled_1f_scenarios_df[\"nfields\"].to_numpy()), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed({1:\"Embedded Vectors\"}),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# in case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=sampled_1f_scenarios_df[\"nfields\"].to_numpy(),with_noise=True, elev=30, azim=30,info_dict={1:\"Embedded Vectors\"},cluster_order=None,title=\"3D Clusters of BART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ced615",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_SPIN_dat_true   = [\"A\" if \"SPIN 0\" in j else \"B\" if (\"SPIN 0\" not in j and \"HEL 1\" not in j) else \"C\" if (\"SPIN 0\" not in j and \"HEL 1\" in j) else \"D\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SPIN_info_dict  = {\"B\":r\"$\\psi_L$\" + \" : LH Fermions\",\"C\":r\"$\\psi_R$\" + \" : RH Fermions\",\"A\":r\"$\\phi$\" + \" : Scalars\" ,\"D\":\"?\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SPIN_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SPIN_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SPIN_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SPIN_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_SU3_dat_true  = [\"3\" if \"SU3 3\" in j else r\"$\\overline{3}$\" if \"SU3 - 3\" in j    else \"1\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU3_info_dict = {\"3\":\"3: Triplets\"     ,r\"$\\overline{3}$\":r\"$\\overline{3}$\" + \": Anti-Triplets\"     ,\"1\":\"1: Singlets\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU3_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU3_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU3_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU3_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_SU2_dat_true  = [3 if \"SU2 3\" in j else 2 if \"SU2 2\" in j    else 1 for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU2_info_dict = {3:\"3 : Triplets\"     ,2:\"2 : Doublets\"     ,1:\"1 : Singlets\" }\n",
    "\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU2_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU2_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU2_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU2_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b9ae3",
   "metadata": {},
   "source": [
    "### TAKEAWAY : Embedding shows whether it had \"understood\" concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77787d14",
   "metadata": {},
   "source": [
    "## Oout-Of-Distribution Generalization : Can it go beyond what its trained? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5fcd2",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is your problem's \"data space\" very big? \n",
    "- Is the probably of an unseen case high? \n",
    "- If yes, then chances of OOD data cases are high. \n",
    "- Do you want to think about the next archietcture?\n",
    "\n",
    "Practical Questions : \n",
    "- Can it work with never seen scenarios? What is your OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0297f",
   "metadata": {},
   "source": [
    "### What are OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b4cf6",
   "metadata": {},
   "source": [
    "OOD for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e556f8",
   "metadata": {},
   "source": [
    "![Lagrangian Example](figTeaser1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83434890",
   "metadata": {},
   "source": [
    "OOD for addition\n",
    "- Trained on numbers up to 100 \n",
    "- Test it on numbers beyond 100 \n",
    "\n",
    "OOD for Lagrangians\n",
    "- Trained on Lagrangians with 6 Fields\n",
    "- Test it on Lagrangians beyond 6 Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ac954c",
   "metadata": {},
   "source": [
    "### U1 Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab69658f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f74d553",
   "metadata": {},
   "source": [
    "### N field Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873438d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55da998",
   "metadata": {},
   "source": [
    "# Acknowledge SUPR\n",
    "The computations and data handling were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS) from projects NAISS 2025/22-521, partially funded by the Swedish Research Council through grant agreement no. 2022-06725"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
