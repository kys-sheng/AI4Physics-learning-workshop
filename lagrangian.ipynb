{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369682e",
   "metadata": {},
   "source": [
    "## ðŸŽ“ Part 2: Tackling a Realistic Physics Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f6a62",
   "metadata": {},
   "source": [
    "# Model Task:\n",
    "<img src=\"https://i.imgur.com/dGfUOPB.png\" alt=\"Distribtuion\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66de86d",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca49607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose GPU if available\n",
    "import torch\n",
    "import pandas as pd\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "964c4027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name   = \"JoseEliel/BART-Lagrangian\"\n",
    "model        = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 0 SU3 3 SU2 2 U1 - 7 / 2 [EOS]\n",
      "token_id =  [0, 22, 36, 9, 38, 10, 37, 6, 39, 7, 14, 4, 6, 1]\n",
      "decoded  =  [SOS] FIELD SPIN 0 SU3 3 SU2 2 U1 - 7 / 2 [EOS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_input = \"[SOS] FIELD SPIN 0 SU3 3 SU2 2 U1 - 7 / 2 [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0586ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # loss with labels_1 and labels_2\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0), max_length=1024)\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted : \", )\n",
    "for i in le.sep_terms(predicted_string):\n",
    "    print(\" \".join(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaae72",
   "metadata": {},
   "source": [
    "# <u>**Learning outcomes**</u> :  Considerations needed in each step of a project!\n",
    "- Essentially, in each step of your project, things to consider\n",
    "- In reality, what will be relevant are heavily dependent on your project in mind!\n",
    "- we will use a mixture of mathematics example and example from Lagrangian task\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e25c63",
   "metadata": {},
   "source": [
    "# <u>Content</u>:\n",
    "<h4>\n",
    "1. Datasets : Distributions and Tokenization <br>\n",
    "2. Training : Where to find resources!<br>\n",
    "3. Evaluations : Metric vs Score, Embedding Analysis, Oout-Of-Domain Generalization<br>\n",
    "</h4>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade93c0",
   "metadata": {},
   "source": [
    "Before anything else, load some basic libraries :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0dcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4dc9c",
   "metadata": {},
   "source": [
    "# 1. **Preparing your Dataset**\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eccef88",
   "metadata": {},
   "source": [
    "## **Rule of Thumb** : NN are good interpolators, but not that good of an extrapolator. (Recall Niklas' talk)\n",
    "- NN learns from data.\n",
    "- If the model is given something it has never seen, it figure outs based on existing experience \n",
    "- Training Data Distribution matters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3ae47",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836574f",
   "metadata": {},
   "source": [
    "# **1a. Data Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972275e",
   "metadata": {},
   "source": [
    "## **What do you need to think about then?**\n",
    "## **Where to start?**  \n",
    "## **Think of your use case, and go from there!**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a605ef",
   "metadata": {},
   "source": [
    "## Example in Math  :\n",
    "<div align=\"center\">\n",
    "     <h2> x + y => ? </h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508ff36",
   "metadata": {},
   "source": [
    "### Use case : add any two numbers independent of the number's digits, <br> be it between 1-digit numbers (2+2) or 5-digit numbers (20000+16378)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3b9d",
   "metadata": {},
   "source": [
    "\n",
    "Let's generate numbers from 1-10000 and do addition as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36f0771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 10000\n",
    "min_num      = 1\n",
    "max_num      = 10000\n",
    "\n",
    "# Generate random examples\n",
    "examples     = [(random.randint(min_num, max_num),random.randint(min_num, max_num)) for _ in range(num_examples)]\n",
    "df           = pd.DataFrame(examples, columns=['x', 'y'])\n",
    "df['sum']    = df['x'] + df['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc760cc6",
   "metadata": {},
   "source": [
    "Lets check the number of digits in each number in our dataset. So,  <br>\n",
    "- <u>7</u> = 1 digit\n",
    "- <u>42</u> = 2 digits\n",
    "- <u>999</u> = 3 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8839a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets compute the number of digits in each number\n",
    "df['x_digit'] = df['x'].apply(lambda x: len(str(x)))    \n",
    "df['y_digit'] = df['y'].apply(lambda x: len(str(x)))    \n",
    "df['sum_digit'] = df['sum'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Plot the distribution of number of digits\n",
    "df['x_digit'].hist(label=\"x\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['y_digit'].hist(label=\"y\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['sum_digit'].hist(label=\"sum\",range=(1,6),bins=5,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of number of digits\")\n",
    "plt.xlabel(\"Number of digits\")  \n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f96d97",
   "metadata": {},
   "source": [
    "### Probability of the model to learn the addition with the **both number** having 1 digit, 2 digits, 3 digits, 4 digits, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10943d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(both_digit=1) =  0.0\n",
      "P(both_digit=2) =  0.01\n",
      "P(both_digit=3) =  0.83\n",
      "P(both_digit=4) =  80.49\n",
      "P(both_digit=5) =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"P(both_digit=1) = \", len(df[(df[\"x_digit\"] == 1) & (df[\"y_digit\"] == 1)]) / num_examples * 100)\n",
    "print(\"P(both_digit=2) = \", len(df[(df[\"x_digit\"] == 2) & (df[\"y_digit\"] == 2)]) / num_examples * 100)\n",
    "print(\"P(both_digit=3) = \", len(df[(df[\"x_digit\"] == 3) & (df[\"y_digit\"] == 3)]) / num_examples * 100)\n",
    "print(\"P(both_digit=4) = \", len(df[(df[\"x_digit\"] == 4) & (df[\"y_digit\"] == 4)]) / num_examples * 100)\n",
    "print(\"P(both_digit=5) = \", len(df[(df[\"x_digit\"] == 5) & (df[\"y_digit\"] == 5)]) / num_examples * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07424",
   "metadata": {},
   "source": [
    "### Probability of the model to learn additions that leads to a sum with 1 digit, 2 digits, 3 digits, 4 digits, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1498d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(sum_digit=1) =  0.0\n",
      "P(sum_digit=2) =  0.0\n",
      "P(sum_digit=3) =  0.5\n",
      "P(sum_digit=4) =  49.46\n",
      "P(sum_digit=5) =  50.03999999999999\n"
     ]
    }
   ],
   "source": [
    "print(\"P(sum_digit=1) = \", len(df[df[\"sum_digit\"] == 1]) / num_examples* 100)\n",
    "print(\"P(sum_digit=2) = \", len(df[df[\"sum_digit\"] == 2]) / num_examples* 100)\n",
    "print(\"P(sum_digit=3) = \", len(df[df[\"sum_digit\"] == 3]) / num_examples* 100)\n",
    "print(\"P(sum_digit=4) = \", len(df[df[\"sum_digit\"] == 4]) / num_examples* 100)\n",
    "print(\"P(sum_digit=5) = \", len(df[df[\"sum_digit\"] == 5]) / num_examples* 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82add299",
   "metadata": {},
   "source": [
    "What you should do is actual oversample the existing cases!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0d9ba9",
   "metadata": {},
   "source": [
    "Reference : \n",
    "- https://arxiv.org/pdf/2308.15594 : Shows how Data Distribution affects GCD usecase\n",
    "- https://arxiv.org/abs/2310.02989 : introduce Continuous Numerical Tokenization [Treat numbers as numbers instead of alphabet like]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2eeb50",
   "metadata": {},
   "source": [
    "## Example in Lagrangian example [Skip]\n",
    "<div align=\"center\">\n",
    "     <h2> A , B -> L(A,B,C) </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d88e50",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/dGfUOPB.png\" alt=\"Distribtuion\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f97dcc",
   "metadata": {},
   "source": [
    "Reference: https://arxiv.org/abs/2501.09729\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4b481",
   "metadata": {},
   "source": [
    "### Use Case : <br> A. Want to work with different number of fields <br> B. Want work with varying interactions <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc59d80",
   "metadata": {},
   "source": [
    "We generated two datasets to look into this: \n",
    "- One with more trilinears (harder to get if randomly sample) but less large number of fields\n",
    "- One randomly sampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba04bac",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/K7p8fLR.png\" alt=\"Distribtuion\" width=\"500\">\n",
    "    <p><em>Figure 1: Sampled Distribution.</em></p>\n",
    "    <img src=\"https://i.imgur.com/s4MJA9v.png\" alt=\"Distribtuion\" width=\"500\">\n",
    "    <p><em>Figure 2: Uniform Distribution.</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598fd17",
   "metadata": {},
   "source": [
    "### Results by nfields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75489387",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/CydNCo8.png\" alt=\"Distribtuion\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a442f",
   "metadata": {},
   "source": [
    "Reference : Train set priming https://arxiv.org/abs/2306.15400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc126825",
   "metadata": {},
   "source": [
    "### Results by trilinears"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebd488d",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/tK2izbI.png\" alt=\"Distribtuion\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c7aa2",
   "metadata": {},
   "source": [
    "# TAKEAWAY: What's your use case and build your data around that!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032383a",
   "metadata": {},
   "source": [
    "# **1b. Tokenization choices**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c9f92",
   "metadata": {},
   "source": [
    "## Considerations: \n",
    "- What information is required for your model to learn?\n",
    "- Do you care about expressivity? \n",
    "- Do you care about Out-of-Distribution scenarios?\n",
    "\n",
    "## Practical \n",
    "- How much information?\n",
    "- Vocabulary Size?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e1250b",
   "metadata": {},
   "source": [
    "### Choices of Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0833bf0",
   "metadata": {},
   "source": [
    "In Language:\n",
    "Example Phrase : AI For Physics\n",
    "- Word-Level : AI, For, Physics\n",
    "- Character-Level : A, I,  , F, o, r,  , P, h, y, s, i, c, s\n",
    "\n",
    "In Math:\n",
    "Example Expression : 100 + 420 = 520\n",
    "- \"Term\"-level : 100, +, 420, =, 520\n",
    "- \"Digit\"-Level : 1, 0, 0,  +,  4, 2, 0, =,  5, 2, 0\n",
    "\n",
    "In Lagrangians:\n",
    "Example Field : Higgs Particle\n",
    "- Symbol Level : H\n",
    "- Quantum-Numbers-Level: FIELD, SPIN, 0, SU2, 2, U1, 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddda171",
   "metadata": {},
   "source": [
    "Remark: \n",
    "1. Detailed tokenization : \n",
    "- less vocabulary\n",
    "- more expressive\n",
    "- more token per sequence\n",
    "- heavy on attention mechanism\n",
    "2. Coarse tokenization : \n",
    "- more vocabulary\n",
    "- less expressive\n",
    "- less token per sequence\n",
    "- easier on attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88417b",
   "metadata": {},
   "source": [
    "# Example : Tokenization of numbers  [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4674bd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# Character-level \n",
    "# 1. Generate arithmetic corpus\n",
    "char_level_corpus = [\" \".join(list(f\"{a}+{b}={str(a + b)}\")) for a in range(1000) for b in range(1000)]\n",
    "vocab = {\"1\" : 1, \"2\" : 2, \"3\" : 3, \"4\" : 4, \"5\" : 5, \"6\" : 6, \"7\" : 7, \"8\" : 8, \"9\" : 9,\n",
    "         \"0\" : 0, \"+\" : 10, \"=\" : 11,\"[UNK]\" : 12, \"[PAD]\" : 13, \"[BOS]\" : 14, \"[EOS]\" : 15}\n",
    "# 2. Initialize tokenizer components\n",
    "char_level_tokenizer = Tokenizer(WordLevel(vocab=vocab, unk_token=\"[UNK]\"))\n",
    "char_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "\n",
    "# Word-level \n",
    "word_level_corpus = [f\"{a} + {b} = {str(a + b)}\" for a in range(1000) for b in range(1000)]\n",
    "word_level_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "word_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    "trainer = WordLevelTrainer(special_tokens=special_tokens)\n",
    "word_level_tokenizer.train_from_iterator(word_level_corpus, trainer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7084ce",
   "metadata": {},
   "source": [
    "lets see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c3bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_example :  8 5 5 + 6 7 5 = 1 5 3 0\n",
      "char_level_tokens  :  ['8', '5', '5', '+', '6', '7', '5', '=', '1', '5', '3', '0']\n",
      "char_level_Ntokens :  12\n",
      "\n",
      "word_level_example :  439 + 390 = 829\n",
      "word_level_tokens  :  ['439', '+', '390', '=', '829']\n",
      "word_level_Ntokens :  5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_level_example = random.choice(char_level_corpus)\n",
    "print(\"char_level_example : \",char_level_example)\n",
    "print(\"char_level_tokens  : \",char_level_tokenizer.encode(char_level_example).tokens)\n",
    "print(\"char_level_Ntokens : \",len(char_level_tokenizer.encode(char_level_example).tokens),end=\"\\n\\n\")\n",
    "\n",
    "word_level_example = random.choice(word_level_corpus)\n",
    "print(\"word_level_example : \",word_level_example)\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(word_level_example).tokens)\n",
    "print(\"word_level_Ntokens : \",len(word_level_tokenizer.encode(word_level_example).tokens),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e0e18c",
   "metadata": {},
   "source": [
    "Lets check vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a761b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_vocab_size:  16\n",
      "word_level_vocab_size:  2005\n"
     ]
    }
   ],
   "source": [
    "print(\"char_level_vocab_size: \",char_level_tokenizer.get_vocab_size())\n",
    "print(\"word_level_vocab_size: \",word_level_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89e264e",
   "metadata": {},
   "source": [
    "Try encoding 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6f466c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char_level_tokens  :  ['1', '0', '0', '0', '0']\n",
      "\n",
      "word_level_tokens  :  ['[UNK]']\n",
      "\n",
      "word_level_tokens  :  ['10', '0', '0', '0']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OOD_char_level_example =   \"1 0 0 0 0\"\n",
    "print(\"char_level_tokens  : \",char_level_tokenizer.encode(OOD_char_level_example).tokens,end=\"\\n\\n\")\n",
    "\n",
    "OOD_word_level_example =   \"10000\"\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(OOD_word_level_example).tokens,end=\"\\n\\n\")\n",
    "\n",
    "# Something like this is possible but not intuitive (words and number are slightly different)\n",
    "OOD_word_level_example =   \"10 0 0 0\"\n",
    "print(\"word_level_tokens  : \",word_level_tokenizer.encode(OOD_word_level_example).tokens,end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad87274",
   "metadata": {},
   "source": [
    "# Example : Quantum Field Symbols  [Optional]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f1e9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  FIELD SPIN 0 SU2 3 FIELD SPIN 1/2 SU2 2 U1 8 / 9 HEL -1/2 FIELD SPIN 0 SU3 - 3 SU2 3 U1 1 / 9\n",
      "token_id =  [22, 36, 9, 37, 10, 22, 36, 5, 4, 6, 37, 6, 39, 15, 4, 16, 23, 7, 5, 4, 6, 22, 36, 9, 38, 7, 10, 37, 10, 39, 5, 4, 16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 03:39:24.072660: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-10 03:39:24.310591: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-10 03:39:25.620747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoded  =  FIELD SPIN 0 SU2 3 FIELD SPIN 1 / 2 SU2 2 U1 8 / 9 HEL - 1 / 2 FIELD SPIN 0 SU3 - 3 SU2 3 U1 1 / 9\n"
     ]
    }
   ],
   "source": [
    "from transformers import  PreTrainedTokenizerFast\n",
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"JoseEliel/BART-Lagrangian\")\n",
    "sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "\n",
    "example = sampled_df.sample(1)[\"fields\"].values[0]\n",
    "print(\"Input    = \",example)\n",
    "encoded = hf_tokenizer.encode(example)\n",
    "print(\"token_id = \", encoded)\n",
    "decoded = hf_tokenizer.decode(encoded)\n",
    "print(\"decoded  = \", decoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d5865a",
   "metadata": {},
   "source": [
    "#### TAKEAWAY : THe level of tokenization affects attention usage and vocab size \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f152260",
   "metadata": {},
   "source": [
    "# Training : Where to find resources?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5a3b8",
   "metadata": {},
   "source": [
    "### NAISS : https://www.naiss.se/\n",
    "- Provider of compute and storage resources\n",
    "- For any researchers based in Sweden\n",
    "\n",
    "### SUPR : https://supr.naiss.se/\n",
    "- Portal to apply for it. \n",
    "- There are varyind levels of applications [small, medium, large]\n",
    "- PhD students and above can already apply for small compute (Alvis: 1000GPUhs/months and Dardel: 20000 CPU-h/month!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dafdc",
   "metadata": {},
   "source": [
    "\n",
    "# For GPU recommend:\n",
    "### Alvis : https://www.c3se.chalmers.se/about/Alvis/ <br> OnDemand Portal : https://alvis.c3se.chalmers.se/pun/sys/dashboard/\n",
    "\n",
    "### Dardel : https://www.pdc.kth.se/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926aecc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9823e0",
   "metadata": {},
   "source": [
    "# 3. Evaluation\n",
    "\n",
    "<h2>\n",
    "To evaluate your model, again, think of your use case:\n",
    "</h2>\n",
    "\n",
    "<h3>\n",
    "A. Is Cross-Entropy Loss enough for your model?  (Think about permutation invariance, conservation laws, ...)\n",
    "  <ul>\n",
    "    <li> Yes? -> Continue </li>\n",
    "    <li> No? -> Create your own metric</li>\n",
    "  </ul>\n",
    "B. Do you care whether the model internalizes the right concepts? (Relationship between symbols, or between inputs and outputs) \n",
    "  <ul>\n",
    "    <li> Yes? -> Embedding Analysis</li> PICTURE\n",
    "    <li> No? -> Continue </li>\n",
    "  </ul>\n",
    "C. Is your problem \"infinite\"(ie probability of getting an unseen data point is high)?  \n",
    "  <ul>\n",
    "    <li>Yes? -> OoD Generalization</li>\n",
    "    <li>No? -> Continue </li>\n",
    "  </ul>\n",
    "</h3>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b2ab6",
   "metadata": {},
   "source": [
    "## 3A. Existing Metric  : Does it work? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c788b83",
   "metadata": {},
   "source": [
    "mainly to see if things work as expected\n",
    "Loss : Deviation from actual term \n",
    "Accuracy : How much is perfect? \n",
    "New metric, Score : (Order does not always matter, XEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de2039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 11:23:55.909590: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-10 11:23:55.956207: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-10 11:23:56.745335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking Tokens Format\n",
      "particle_id_token          :  ['ID1']\n",
      "derivative_id_token        :  ['ID1']\n",
      "gamma_id_token             :  ['ID1']\n",
      "sigma_id_token(1)          :  ['ID1']\n",
      "spin_token(0)              :  ['SPIN', '0']\n",
      "spin_token(1)              :  ['SPIN', '1']\n",
      "spin_token(Fraction(1,2))  :  ['SPIN', '1/2']\n",
      "helicity_token(1)          :  ['HEL', '1/2']\n",
      "helicity_token(-1)         :  ['HEL', '-1/2']\n",
      "group_tokens(1)            :  ['U1']\n",
      "group_tokens(1,test)            :  ['U1', '_{test}']\n",
      "group_tokens(2)            :  ['SU2']\n",
      "group_tokens(2,test)            :  ['SU2', '_{test}']\n",
      "group_tokens(3)            :  ['SU3']\n",
      "group_tokens(3,test)            :  ['SU3', '_{test}']\n",
      "Tokens Format OK\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available\n",
    "import torch\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name = \"JoseEliel/BART-Lagrangian\"\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25d150b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data if not already loaded, drop duplicates\n",
    "sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "sampled_df.drop_duplicates(subset=[\"fields\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1b2fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields</th>\n",
       "      <th>Lagrangian</th>\n",
       "      <th>train/eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIELD SPIN 1/2 SU3 - 3 SU2 2 U1 - 4 HEL 1/2 FI...</td>\n",
       "      <td>+ FIELD SPIN 1 / 2 SU3 - 3 SU2 2 HEL - 1 / 2 D...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIELD SPIN 1/2 HEL 1/2 FIELD SPIN 1/2 SU3 - 3 ...</td>\n",
       "      <td>+ i FIELD SPIN 1 / 2 HEL 1 / 2 ID9 SIGMA_BAR I...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIELD SPIN 0 SU2 3 U1 - 4 / 9 FIELD SPIN 1/2 S...</td>\n",
       "      <td>+ FIELD SPIN 0 SU2 3 U1 - 4 / 9 ID1 FIELD SPIN...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIELD SPIN 1/2 SU3 - 3 U1 3 / 8 HEL -1/2 FIELD...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 8 / 9 ID3 FI...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 3 SU2 3 ID4 FIELD SPIN 0 SU...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286076</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3 U1 9 / 2 FIELD SPIN 1...</td>\n",
       "      <td>+ FIELD SPIN 1 / 2 SU2 2 U1 1 / 5 HEL - 1 / 2 ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286077</th>\n",
       "      <td>FIELD SPIN 0 FIELD SPIN 0 SU3 3 SU2 3 U1 7 / 6...</td>\n",
       "      <td>+ FIELD SPIN 0 ID1 FIELD SPIN 0 SU3 3 SU2 3 U1...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286078</th>\n",
       "      <td>FIELD SPIN 0 SU3 - 3 U1 3 FIELD SPIN 1/2 SU3 3...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 U1 3 ID4 FIELD SPIN 0 S...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286079</th>\n",
       "      <td>FIELD SPIN 1/2 U1 - 4 / 5 HEL -1/2 FIELD SPIN ...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 1 / 7 ID6 FI...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286080</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 FIELD SPIN 1/2...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 ID0 FIELD SP...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211283 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fields  \\\n",
       "0       FIELD SPIN 1/2 SU3 - 3 SU2 2 U1 - 4 HEL 1/2 FI...   \n",
       "1       FIELD SPIN 1/2 HEL 1/2 FIELD SPIN 1/2 SU3 - 3 ...   \n",
       "2       FIELD SPIN 0 SU2 3 U1 - 4 / 9 FIELD SPIN 1/2 S...   \n",
       "3       FIELD SPIN 1/2 SU3 - 3 U1 3 / 8 HEL -1/2 FIELD...   \n",
       "4                                FIELD SPIN 0 SU3 3 SU2 3   \n",
       "...                                                   ...   \n",
       "286076  FIELD SPIN 0 SU3 3 SU2 3 U1 9 / 2 FIELD SPIN 1...   \n",
       "286077  FIELD SPIN 0 FIELD SPIN 0 SU3 3 SU2 3 U1 7 / 6...   \n",
       "286078  FIELD SPIN 0 SU3 - 3 U1 3 FIELD SPIN 1/2 SU3 3...   \n",
       "286079  FIELD SPIN 1/2 U1 - 4 / 5 HEL -1/2 FIELD SPIN ...   \n",
       "286080  FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 FIELD SPIN 1/2...   \n",
       "\n",
       "                                               Lagrangian train/eval  \n",
       "0       + FIELD SPIN 1 / 2 SU3 - 3 SU2 2 HEL - 1 / 2 D...       eval  \n",
       "1       + i FIELD SPIN 1 / 2 HEL 1 / 2 ID9 SIGMA_BAR I...       eval  \n",
       "2       + FIELD SPIN 0 SU2 3 U1 - 4 / 9 ID1 FIELD SPIN...       eval  \n",
       "3       + FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 8 / 9 ID3 FI...       eval  \n",
       "4       + FIELD SPIN 0 SU3 3 SU2 3 ID4 FIELD SPIN 0 SU...       eval  \n",
       "...                                                   ...        ...  \n",
       "286076  + FIELD SPIN 1 / 2 SU2 2 U1 1 / 5 HEL - 1 / 2 ...      train  \n",
       "286077  + FIELD SPIN 0 ID1 FIELD SPIN 0 SU3 3 SU2 3 U1...      train  \n",
       "286078  + FIELD SPIN 0 SU3 - 3 U1 3 ID4 FIELD SPIN 0 S...      train  \n",
       "286079  + FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 1 / 7 ID6 FI...      train  \n",
       "286080  + FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 ID0 FIELD SP...      train  \n",
       "\n",
       "[211283 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5498f",
   "metadata": {},
   "source": [
    "### Example : Lagrangian Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b01da",
   "metadata": {},
   "source": [
    "Choose a random lagrangian to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18376d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_scenario = sampled_df.sample(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709e360",
   "metadata": {},
   "source": [
    "Look at the input (field content) and the output (Lagrangian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57c89747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 1/2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1/2 FIELD SPIN 0 FIELD SPIN 0 U1 3 / 4 [EOS]\n",
      "token_id =  [0, 22, 36, 5, 4, 6, 38, 7, 10, 37, 6, 39, 7, 5, 4, 10, 23, 5, 4, 6, 22, 36, 9, 22, 36, 9, 39, 10, 4, 11, 1]\n",
      "decoded  =  [SOS] FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 FIELD SPIN 0 FIELD SPIN 0 U1 3 / 4 [EOS]\n",
      "\n",
      "Output   =  [SOS] + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS [EOS]\n",
      "token_id =  [0, 8, 22, 36, 9, 29, 22, 36, 9, 39, 10, 4, 11, 32, 22, 36, 9, 39, 7, 10, 4, 11, 20, 27, 8, 22, 36, 9, 29, 22, 36, 9, 31, 22, 36, 9, 30, 8, 22, 36, 9, 31, 22, 36, 9, 25, 22, 36, 9, 39, 10, 4, 11, 28, 22, 36, 9, 39, 7, 10, 4, 11, 20, 26, 8, 22, 36, 9, 32, 22, 36, 9, 30, 22, 36, 9, 29, 22, 36, 9, 24, 8, 22, 36, 9, 39, 10, 4, 11, 24, 22, 36, 9, 39, 10, 4, 11, 33, 22, 36, 9, 39, 7, 10, 4, 11, 20, 32, 22, 36, 9, 39, 7, 10, 4, 11, 20, 29, 8, 40, 22, 36, 5, 4, 6, 38, 7, 10, 37, 6, 39, 7, 5, 4, 10, 23, 5, 4, 6, 24, 35, 30, 21, 38, 37, 39, 25, 22, 36, 5, 4, 6, 38, 10, 37, 6, 39, 5, 4, 10, 23, 7, 5, 4, 6, 20, 27, 19, 34, 30, 25, 34, 30, 24, 27, 38, 24, 27, 37, 24, 27, 8, 21, 26, 22, 36, 9, 20, 28, 21, 24, 22, 36, 9, 30, 19, 34, 26, 24, 8, 21, 39, 26, 22, 36, 9, 39, 7, 10, 4, 11, 20, 25, 21, 39, 33, 22, 36, 9, 39, 10, 4, 11, 27, 19, 34, 26, 33, 7, 17, 21, 38, 33, 18, 21, 38, 29, 17, 21, 38, 25, 18, 21, 38, 26, 19, 34, 33, 25, 34, 29, 26, 7, 17, 21, 37, 32, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 33, 19, 34, 32, 31, 34, 24, 33, 7, 17, 21, 39, 24, 18, 21, 39, 28, 17, 21, 39, 27, 18, 21, 39, 26, 19, 34, 24, 27, 34, 28, 26, 8, 22, 36, 9, 20, 24, 22, 36, 9, 25, 19, 8, 22, 36, 9, 39, 7, 10, 4, 11, 20, 24, 22, 36, 9, 39, 10, 4, 11, 31, 19, 1]\n",
      "decoded  =  [SOS] + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS [EOS]\n"
     ]
    }
   ],
   "source": [
    "example = example_scenario[\"fields\"].values[0]\n",
    "example_input = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n",
    "print()\n",
    "example = example_scenario[\"Lagrangian\"].values[0]\n",
    "example_output = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Output   = \",example_output)\n",
    "encoded_output = hf_tokenizer.encode(example_output)\n",
    "print(\"token_id = \", encoded_output)\n",
    "decoded_output = hf_tokenizer.decode(encoded_output)\n",
    "print(\"decoded  = \", decoded_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc9f9",
   "metadata": {},
   "source": [
    "Look at the output (Lagrangian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecab14d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output   =  [SOS] + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS [EOS]\n",
      "token_id =  [0, 8, 22, 36, 9, 29, 22, 36, 9, 39, 10, 4, 11, 32, 22, 36, 9, 39, 7, 10, 4, 11, 20, 27, 8, 22, 36, 9, 29, 22, 36, 9, 31, 22, 36, 9, 30, 8, 22, 36, 9, 31, 22, 36, 9, 25, 22, 36, 9, 39, 10, 4, 11, 28, 22, 36, 9, 39, 7, 10, 4, 11, 20, 26, 8, 22, 36, 9, 32, 22, 36, 9, 30, 22, 36, 9, 29, 22, 36, 9, 24, 8, 22, 36, 9, 39, 10, 4, 11, 24, 22, 36, 9, 39, 10, 4, 11, 33, 22, 36, 9, 39, 7, 10, 4, 11, 20, 32, 22, 36, 9, 39, 7, 10, 4, 11, 20, 29, 8, 40, 22, 36, 5, 4, 6, 38, 7, 10, 37, 6, 39, 7, 5, 4, 10, 23, 5, 4, 6, 24, 35, 30, 21, 38, 37, 39, 25, 22, 36, 5, 4, 6, 38, 10, 37, 6, 39, 5, 4, 10, 23, 7, 5, 4, 6, 20, 27, 19, 34, 30, 25, 34, 30, 24, 27, 38, 24, 27, 37, 24, 27, 8, 21, 26, 22, 36, 9, 20, 28, 21, 24, 22, 36, 9, 30, 19, 34, 26, 24, 8, 21, 39, 26, 22, 36, 9, 39, 7, 10, 4, 11, 20, 25, 21, 39, 33, 22, 36, 9, 39, 10, 4, 11, 27, 19, 34, 26, 33, 7, 17, 21, 38, 33, 18, 21, 38, 29, 17, 21, 38, 25, 18, 21, 38, 26, 19, 34, 33, 25, 34, 29, 26, 7, 17, 21, 37, 32, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 33, 19, 34, 32, 31, 34, 24, 33, 7, 17, 21, 39, 24, 18, 21, 39, 28, 17, 21, 39, 27, 18, 21, 39, 26, 19, 34, 24, 27, 34, 28, 26, 8, 22, 36, 9, 20, 24, 22, 36, 9, 25, 19, 8, 22, 36, 9, 39, 7, 10, 4, 11, 20, 24, 22, 36, 9, 39, 10, 4, 11, 31, 19, 1]\n",
      "decoded  =  [SOS] + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS [EOS]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e8dc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five terms: \n",
      "term 1 :  + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3\n",
      "term 2 :  + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6\n",
      "term 3 :  + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2\n",
      "term 4 :  + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0\n",
      "term 5 :  + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5\n"
     ]
    }
   ],
   "source": [
    "# show the terms \n",
    "separated_terms = le.sep_terms(decoded_output)\n",
    "\n",
    "print(\"First five terms: \")\n",
    "for i in range(len(separated_terms)):\n",
    "    if i>4: break\n",
    "    print(f\"term {i+1} : \",\" \".join(separated_terms[i]))\n",
    "    \n",
    "lag_truth_1 =  \" \".join([\" \".join(i) for i in separated_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd382b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five terms after reordering: \n",
      "term 1 :  + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6\n",
      "term 2 :  + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3\n",
      "term 3 :  + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2\n",
      "term 4 :  + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0\n",
      "term 5 :  + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5\n"
     ]
    }
   ],
   "source": [
    "# reorder the first and second terms using list \n",
    "separated_terms[0],separated_terms[1] = separated_terms[1],separated_terms[0]\n",
    "\n",
    "print(\"First five terms after reordering: \")\n",
    "for i in range(len(separated_terms)):\n",
    "    if i>4: break\n",
    "    print(f\"term {i+1} : \",\" \".join(separated_terms[i]))\n",
    "lag_truth_2 =  \" \".join([\" \".join(i) for i in separated_terms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aa1e60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " [0, 22, 36, 5, 4, 6, 38, 7, 10, 37, 6, 39, 7, 5, 4, 10, 23, 5, 4, 6, 22, 36, 9, 22, 36, 9, 39, 10, 4, 11, 1]\n",
      "\n",
      "Outputs:\n",
      "labels_1:  tensor([[ 0,  8, 22, 36,  9, 29, 22, 36,  9, 39, 10,  4, 11, 32, 22, 36,  9, 39,\n",
      "          7, 10,  4, 11, 20, 27,  8, 22, 36,  9, 29, 22, 36,  9, 31, 22, 36,  9,\n",
      "         30,  8, 22, 36,  9, 31, 22, 36,  9, 25, 22, 36,  9, 39, 10,  4, 11, 28,\n",
      "         22, 36,  9, 39,  7, 10,  4, 11, 20, 26,  8, 22, 36,  9, 32, 22, 36,  9,\n",
      "         30, 22, 36,  9, 29, 22, 36,  9, 24,  8, 22, 36,  9, 39, 10,  4, 11, 24,\n",
      "         22, 36,  9, 39, 10,  4, 11, 33, 22, 36,  9, 39,  7, 10,  4, 11, 20, 32,\n",
      "         22, 36,  9, 39,  7, 10,  4, 11, 20, 29,  8, 40, 22, 36,  5,  4,  6, 38,\n",
      "          7, 10, 37,  6, 39,  7,  5,  4, 10, 23,  5,  4,  6, 24, 35, 30, 21, 38,\n",
      "         37, 39, 25, 22, 36,  5,  4,  6, 38, 10, 37,  6, 39,  5,  4, 10, 23,  7,\n",
      "          5,  4,  6, 20, 27, 19, 34, 30, 25, 34, 30, 24, 27, 38, 24, 27, 37, 24,\n",
      "         27,  8, 21, 26, 22, 36,  9, 20, 28, 21, 24, 22, 36,  9, 30, 19, 34, 26,\n",
      "         24,  8, 21, 39, 26, 22, 36,  9, 39,  7, 10,  4, 11, 20, 25, 21, 39, 33,\n",
      "         22, 36,  9, 39, 10,  4, 11, 27, 19, 34, 26, 33,  7, 17, 21, 38, 33, 18,\n",
      "         21, 38, 29, 17, 21, 38, 25, 18, 21, 38, 26, 19, 34, 33, 25, 34, 29, 26,\n",
      "          7, 17, 21, 37, 32, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 33, 19,\n",
      "         34, 32, 31, 34, 24, 33,  7, 17, 21, 39, 24, 18, 21, 39, 28, 17, 21, 39,\n",
      "         27, 18, 21, 39, 26, 19, 34, 24, 27, 34, 28, 26,  8, 22, 36,  9, 20, 24,\n",
      "         22, 36,  9, 25, 19,  8, 22, 36,  9, 39,  7, 10,  4, 11, 20, 24, 22, 36,\n",
      "          9, 39, 10,  4, 11, 31, 19,  1]])\n",
      "labels_2:  tensor([[ 0,  8, 22, 36,  9, 29, 22, 36,  9, 31, 22, 36,  9, 30,  8, 22, 36,  9,\n",
      "         29, 22, 36,  9, 39, 10,  4, 11, 32, 22, 36,  9, 39,  7, 10,  4, 11, 20,\n",
      "         27,  8, 22, 36,  9, 31, 22, 36,  9, 25, 22, 36,  9, 39, 10,  4, 11, 28,\n",
      "         22, 36,  9, 39,  7, 10,  4, 11, 20, 26,  8, 22, 36,  9, 32, 22, 36,  9,\n",
      "         30, 22, 36,  9, 29, 22, 36,  9, 24,  8, 22, 36,  9, 39, 10,  4, 11, 24,\n",
      "         22, 36,  9, 39, 10,  4, 11, 33, 22, 36,  9, 39,  7, 10,  4, 11, 20, 32,\n",
      "         22, 36,  9, 39,  7, 10,  4, 11, 20, 29,  8, 40, 22, 36,  5,  4,  6, 38,\n",
      "          7, 10, 37,  6, 39,  7,  5,  4, 10, 23,  5,  4,  6, 24, 35, 30, 21, 38,\n",
      "         37, 39, 25, 22, 36,  5,  4,  6, 38, 10, 37,  6, 39,  5,  4, 10, 23,  7,\n",
      "          5,  4,  6, 20, 27, 19, 34, 30, 25, 34, 30, 24, 27, 38, 24, 27, 37, 24,\n",
      "         27,  8, 21, 26, 22, 36,  9, 20, 28, 21, 24, 22, 36,  9, 30, 19, 34, 26,\n",
      "         24,  8, 21, 39, 26, 22, 36,  9, 39,  7, 10,  4, 11, 20, 25, 21, 39, 33,\n",
      "         22, 36,  9, 39, 10,  4, 11, 27, 19, 34, 26, 33,  7, 17, 21, 38, 33, 18,\n",
      "         21, 38, 29, 17, 21, 38, 25, 18, 21, 38, 26, 19, 34, 33, 25, 34, 29, 26,\n",
      "          7, 17, 21, 37, 32, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 33, 19,\n",
      "         34, 32, 31, 34, 24, 33,  7, 17, 21, 39, 24, 18, 21, 39, 28, 17, 21, 39,\n",
      "         27, 18, 21, 39, 26, 19, 34, 24, 27, 34, 28, 26,  8, 22, 36,  9, 20, 24,\n",
      "         22, 36,  9, 25, 19,  8, 22, 36,  9, 39,  7, 10,  4, 11, 20, 24, 22, 36,\n",
      "          9, 39, 10,  4, 11, 31, 19,  1]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs:\\n\", encoded_input)\n",
    "print()\n",
    "\n",
    "print(\"Outputs:\",)\n",
    "targets_1 = hf_tokenizer(\"[SOS] \" + lag_truth_1 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True)\n",
    "targets_2 = hf_tokenizer(\"[SOS] \" + lag_truth_2 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "#print(\"targets_1: \", targets_1)\n",
    "labels_1 = targets_1[\"input_ids\"]\n",
    "#print(\"targets_2: \", targets_2)\n",
    "labels_2 = targets_2[\"input_ids\"]\n",
    "\n",
    "\n",
    "#print(\"inputs: \", hf_tokenizer.decode(encoded_input))\n",
    "print(\"labels_1: \", labels_1)\n",
    "#print(\"labels_1: \", hf_tokenizer.decode(labels_1[0]))\n",
    "print(\"labels_2: \", labels_2)\n",
    "#print(\"labels_2: \", hf_tokenizer.decode(labels_2[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffd64d",
   "metadata": {},
   "source": [
    "Generate the Lagrangians and calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07006038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss with labels_1: tensor(0.2972)\n",
      "loss with labels_2: tensor(0.4060)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # loss with labels_1 and labels_2\n",
    "    outputs_1 = model(input_ids=torch.tensor(encoded_input).unsqueeze(0), labels=labels_1)\n",
    "    print(\"loss with labels_1:\", outputs_1.loss)\n",
    "    \n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_1 = torch.argmax(outputs_1.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_1 = hf_tokenizer.decode(predicted_token_ids_1[0], skip_special_tokens=True)\n",
    "    \n",
    "    outputs_2 = model(input_ids=torch.tensor(encoded_input).unsqueeze(0), labels=labels_2)\n",
    "    print(\"loss with labels_2:\", outputs_2.loss)\n",
    "\n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_2 = torch.argmax(outputs_2.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_2 = hf_tokenizer.decode(predicted_token_ids_2[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get the prediction during inference\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0), max_length=len(labels_1[0]))\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c437825",
   "metadata": {},
   "source": [
    "### TAKEAWAY : LOSS IS NOT ENOUGH!  ORDER/PERMUTATION INVARIANT? Conservation of charges? etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e3634",
   "metadata": {},
   "source": [
    "Calculate the score :\n",
    "\n",
    "<div align=\"center\">\n",
    "     <h2> S_Lagrangian = S_contraction - P_length </h2>\n",
    "</div>\n",
    "\n",
    "where:\n",
    "- S_contraction = N_correct / N_true\n",
    "- P_length      = N_Extra / N_true     \n",
    "- S_object      = N_correct_objects / N_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf03ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction        :  + FIELD SPIN 0 ID8 FIELD SPIN 0 U1 3 / 4 ID6 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID7 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID8 FIELD SPIN 0 ID7 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 FIELD SPIN 0 ID0 FIELD SPIN 0 ID2 + FIELD SPIN 0 U1 3 / 4 ID7 FIELD SPIN 0 U1 3 / 4 ID6 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID4 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID4 SIGMA_BAR ID8 DERIVATIVE SU3 SU2 U1 ID6 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID2 CONTRACTIONS LORENTZ ID8 ID6 LORENTZ ID8 ID4 ID2 SU3 ID4 ID2 SU2 ID4 ID2 + DERIVATIVE ID0 FIELD SPIN 0 DAGGER ID6 DERIVATIVE ID8 FIELD SPIN 0 ID4 CONTRACTIONS LORENTZ ID0 ID8 + DERIVATIVE U1 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 DERIVATIVE U1 ID6 FIELD SPIN 0 U1 3 / 4 ID5 CONTRACTIONS LORENTZ ID4 ID6 - COMMUTATOR_A DERIVATIVE SU3 ID4 COMMUTATOR_B DERIVATIVE SU3 ID8 COMMUTATOR_A DERIVATIVE SU3 ID6 COMMUTATOR_B DERIVATIVE SU3 ID5 CONTRACTIONS LORENTZ ID4 ID6 LORENTZ ID8 ID5 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID8 COMMUTATOR_A DERIVATIVE SU2 ID6 COMMUTATOR_B DERIVATIVE SU2 ID0 CONTRACTIONS LORENTZ ID4 ID6 LORENTZ ID8 ID0 - COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID8 COMMUTATOR_A DERIVATIVE U1 ID6 COMMUTATOR_B DERIVATIVE U1 ID0 CONTRACTIONS LORENTZ ID4 ID6 LORENTZ ID8 ID0 + FIELD SPIN 0 DAGGER ID4 FIELD SPIN 0 ID6 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID4 FIELD SPIN 0 U1 3 / 4 ID8\n",
      "\n",
      "Truth_1           :  + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS\n",
      "Lagrangian score  :  0.9230769230769231\n",
      "Object score      :  0.9230769230769231\n",
      "Contraction Score :  0.9230769230769231\n",
      "Length penalty    :  0.0\n",
      "\n",
      "Truth_2           :  + FIELD SPIN 0 ID5 FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 + FIELD SPIN 0 ID5 FIELD SPIN 0 U1 3 / 4 ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID3 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 FIELD SPIN 0 U1 3 / 4 ID4 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID2 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 ID5 FIELD SPIN 0 ID0 + FIELD SPIN 0 U1 3 / 4 ID0 FIELD SPIN 0 U1 3 / 4 ID9 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID8 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID5 + i FIELD SPIN 1 / 2 SU3 - 3 SU2 2 U1 - 1 / 3 HEL 1 / 2 ID0 SIGMA_BAR ID6 DERIVATIVE SU3 SU2 U1 ID1 FIELD SPIN 1 / 2 SU3 3 SU2 2 U1 1 / 3 HEL - 1 / 2 DAGGER ID3 CONTRACTIONS LORENTZ ID6 ID1 LORENTZ ID6 ID0 ID3 SU3 ID0 ID3 SU2 ID0 ID3 + DERIVATIVE ID2 FIELD SPIN 0 DAGGER ID4 DERIVATIVE ID0 FIELD SPIN 0 ID6 CONTRACTIONS LORENTZ ID2 ID0 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 3 / 4 DAGGER ID1 DERIVATIVE U1 ID9 FIELD SPIN 0 U1 3 / 4 ID3 CONTRACTIONS LORENTZ ID2 ID9 - COMMUTATOR_A DERIVATIVE SU3 ID9 COMMUTATOR_B DERIVATIVE SU3 ID5 COMMUTATOR_A DERIVATIVE SU3 ID1 COMMUTATOR_B DERIVATIVE SU3 ID2 CONTRACTIONS LORENTZ ID9 ID1 LORENTZ ID5 ID2 - COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID9 CONTRACTIONS LORENTZ ID8 ID7 LORENTZ ID0 ID9 - COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 COMMUTATOR_A DERIVATIVE U1 ID3 COMMUTATOR_B DERIVATIVE U1 ID2 CONTRACTIONS LORENTZ ID0 ID3 LORENTZ ID4 ID2 + FIELD SPIN 0 DAGGER ID0 FIELD SPIN 0 ID1 CONTRACTIONS + FIELD SPIN 0 U1 - 3 / 4 DAGGER ID0 FIELD SPIN 0 U1 3 / 4 ID7 CONTRACTIONS\n",
      "Lagrangian score  :  0.9230769230769231\n",
      "Object score      :  0.9230769230769231\n",
      "Contraction Score :  0.9230769230769231\n",
      "Length penalty    :  0.0\n"
     ]
    }
   ],
   "source": [
    "lscore_1, obscore_1, conscore_1, lpen_1 = le.get_lagrangian_score(predicted_string,lag_truth_1)\n",
    "lscore_2, obscore_2, conscore_2, lpen_2 = le.get_lagrangian_score(predicted_string,lag_truth_2)\n",
    "\n",
    "print(\"Prediction        : \", predicted_string)\n",
    "print()\n",
    "print(\"Truth_1           : \", lag_truth_1)\n",
    "print(\"Lagrangian score  : \",lscore_1)\n",
    "print(\"Object score      : \",obscore_1)\n",
    "print(\"Contraction Score : \",conscore_1)\n",
    "print(\"Length penalty    : \",lpen_1)\n",
    "print()\n",
    "print(\"Truth_2           : \", lag_truth_2)\n",
    "print(\"Lagrangian score  : \",lscore_2)\n",
    "print(\"Object score      : \",obscore_2)\n",
    "print(\"Contraction Score : \",conscore_2)\n",
    "print(\"Length penalty    : \",lpen_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf97e2",
   "metadata": {},
   "source": [
    "## 3B. Embedding analysis : What has it really learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72478e40",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is efficiency the only think you need? \n",
    "- Or is it important for you to know whether the model knows what it is learning? \n",
    "\n",
    "Practical Questions : \n",
    "- Can it associate inputs to some embedding space? <br> \n",
    "- Can it understand relations between inputs?  <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7a58d",
   "metadata": {},
   "source": [
    "### What is embedding analysis? Basically information encoded in a learned vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041fe80",
   "metadata": {},
   "source": [
    "<h4> Example in English-German translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60130ae",
   "metadata": {},
   "source": [
    "![Embeddings in LLM](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*52X2L01wpUjy39lIjofC7g.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3bd51",
   "metadata": {},
   "source": [
    "<h4> Example of food words embeddings and their corresponding possible learned axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb71eb",
   "metadata": {},
   "source": [
    "![Embeddings in LLM](https://developers.google.com/static/machine-learning/crash-course/images/embeddings_3D_tangyuan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de8251",
   "metadata": {},
   "source": [
    "### Example : Embeddings of different field symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8e850",
   "metadata": {},
   "source": [
    "Get all the 1-field scenarios' inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dfb9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"nfields\"]   = sampled_df[\"fields\"].apply(lambda x: x.count(\"FIELD\"))\n",
    "sampled_1f_scenarios_df = sampled_df[sampled_df[\"nfields\"]==1]\n",
    "sampled_1f_scenarios_df = sampled_1f_scenarios_df.sample(1000)\n",
    "fields                  = sampled_1f_scenarios_df[\"fields\"].apply(lambda x: set([\"FIELD \"+k for k in x.split(\"FIELD \") if k != \"\"])).to_list()\n",
    "uniq_fields_list_1f     = list(set.union(*(fields)))\n",
    "uniq_fields_list_1f     = [str((\"[SOS] \"+ k + \" [EOS]\").replace(\"  \",\" \")) for k in uniq_fields_list_1f]\n",
    "uniq_fields_list_1f     = np.unique(uniq_fields_list_1f).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9db4d73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 1 / 2 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 1 / 5 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 1 / 7 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 1 / 8 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 2 / 3 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 2 / 9 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 3 / 5 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 4 / 3 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 4 / 5 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 5 / 3 [EOS]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first 10 unique fields\n",
    "for i in uniq_fields_list_1f[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bba06",
   "metadata": {},
   "source": [
    "Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cef2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/tmp/ipykernel_97588/595248388.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_loader  = DataLoader( torch.tensor(inputs_batch[\"input_ids\"]).to(device), batch_size=32)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [05:10<00:00,  9.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "inputs_batch = hf_tokenizer(uniq_fields_list_1f, return_tensors='pt', truncation=True,padding=True).to(device)\n",
    "data_loader  = DataLoader( torch.tensor(inputs_batch[\"input_ids\"]).to(device), batch_size=32)\n",
    "\n",
    "\n",
    "# Example of getting embeddings of specific cases\n",
    "all_embedding_1f = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for xinput in tqdm(data_loader):\n",
    "        outputs = model(xinput.to(device), output_hidden_states=True)\n",
    "        # Get the embeddings, which we choose to be the encoder's last hidden state of the first token\n",
    "        embeddings_enc = outputs.encoder_last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embedding_1f.append( torch.tensor(embeddings_enc))\n",
    "\n",
    "all_embedding_1f = torch.cat(all_embedding_1f, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8bc6f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1024])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embedding_1f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154db3b",
   "metadata": {},
   "source": [
    "Reduced the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "671d4a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:780: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/ys/.local/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:790: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3)\n",
    "tsne_results = tsne.fit_transform(all_embedding_1f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56820673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d998f818",
   "metadata": {},
   "source": [
    "# If no time, start here to load the embeddings instead of generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "885afcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "# In case it takes forever, load the tsne reduced embedding vectors\n",
    "with open(\"./tsne_results.pkl\", 'rb') as f:    tsne_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deaf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_3d_tsne(tsne_results, clusters_dat, with_noise=True,elev=30, azim=30,info_dict=None,cluster_order=None,title=\"3D Clusters of BART\"):\n",
    "    \"\"\"\n",
    "    Plots a 3D scatter plot of t-SNE results\n",
    "    \n",
    "    Parameters:\n",
    "    - tsne_results (numpy.ndarray): The 3D coordinates from t-SNE, shape (n_samples, 3).\n",
    "    - clusters_dat (numpy.ndarray): The cluster labels from DBSCAN, shape (n_samples,).\n",
    "    - elev (float): Elevation angle for the 3D plot.\n",
    "    - azim (float): Azimuthal angle for the 3D plot.\n",
    "    \"\"\"\n",
    "    if cluster_order is None: cluster_order = np.unique(clusters_dat)\n",
    "\n",
    "    colors = plt.colormaps['tab20']\n",
    "    \n",
    "    if info_dict is not None: cluster_colors = {cluster: colors(i) for i, cluster in enumerate(info_dict.keys())}\n",
    "    else                    : cluster_colors = {cluster: colors(i) for i, cluster in enumerate(cluster_order)}\n",
    "\n",
    "    # Create an interactive 3D scatter plot\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    for cluster in cluster_order:\n",
    "        if not with_noise and cluster == -1: continue\n",
    "        cluster_points = tsne_results[np.array(clusters_dat) == cluster]\n",
    "        if info_dict is None:\n",
    "            cluster_label=f'Cluster {cluster}'\n",
    "        else:\n",
    "            try    :cluster_label=f'{info_dict[cluster][\"tag\"]}'\n",
    "            except :cluster_label=f'{info_dict[cluster]}'\n",
    "\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], \n",
    "                       color=cluster_colors[cluster], label=cluster_label, alpha=0.7)\n",
    "\n",
    "    \n",
    "    ax.legend(loc='lower right', fontsize=\"medium\", bbox_to_anchor=(.35, .65))\n",
    "\n",
    "    # Setting labels and title\n",
    "    ax.set_xlabel('TSNE Component 1',fontsize=\"medium\")\n",
    "    ax.set_ylabel('TSNE Component 2',fontsize=\"medium\")\n",
    "    ax.set_zlabel('TSNE Component 3',fontsize=\"medium\")\n",
    "    ax.tick_params(labelsize=\"small\")    # Use ax.set_title() for a 3D plot and adjust the padding\n",
    "    # Use fig.suptitle instead of ax.set_title for better control\n",
    "    fig.suptitle(title, fontsize=\"large\")  # y controls the vertical position; lower values move it closer to the plot\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)  # You can further lower the top value to move the plot down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28c65e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a8a8e40a1754318a1baa566fe199caa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(sampled_1f_scenarios_df[\"nfields\"].to_numpy()), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed({1:\"Embedded Vectors\"}),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\" clusters\")\n",
    "                    )\n",
    "\n",
    "# in case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=sampled_1f_scenarios_df[\"nfields\"].to_numpy(),with_noise=True, elev=30, azim=30,info_dict={1:\"Embedded Vectors\"},cluster_order=None,title=\"3D Clusters of BART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24ced615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52191807e0f044e78ee6e0f436e57a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_SPIN_dat_true   = [\"A\" if \"SPIN 0\" in j else \"B\" if (\"SPIN 0\" not in j and \"HEL 1\" not in j) else \"C\" if (\"SPIN 0\" not in j and \"HEL 1\" in j) else \"D\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SPIN_info_dict  = {\"B\":r\"$\\psi_L$\" + \" : LH Fermions\",\"C\":r\"$\\psi_R$\" + \" : RH Fermions\",\"A\":r\"$\\phi$\" + \" : Scalars\" ,\"D\":\"?\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SPIN_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SPIN_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SPIN_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SPIN_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "875d2326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a73e2adb20347a9b4807b4359f164dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_SU3_dat_true  = [\"3\" if \"SU3 3\" in j else r\"$\\overline{3}$\" if \"SU3 - 3\" in j    else \"1\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU3_info_dict = {\"3\":\"3: Triplets\"     ,r\"$\\overline{3}$\":r\"$\\overline{3}$\" + \": Anti-Triplets\"     ,\"1\":\"1: Singlets\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU3_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU3_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SU3 clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU3_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU3_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7648d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20aa635b28d04c088353cef85b36d908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cluster_SU2_dat_true  = [3 if \"SU2 3\" in j else 2 if \"SU2 2\" in j    else 1 for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU2_info_dict = {3:\"3 : Triplets\"     ,2:\"2 : Doublets\"     ,1:\"1 : Singlets\" }\n",
    "\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU2_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU2_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SU2 clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU2_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU2_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b9ae3",
   "metadata": {},
   "source": [
    "### TAKEAWAY : Embedding shows whether it had \"understood\" concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77787d14",
   "metadata": {},
   "source": [
    "## 3C. Out-Of-Distribution Generalization : Can it go beyond what its trained? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5fcd2",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is your problem's \"data space\" very big? \n",
    "- Is the probably of an unseen case high? \n",
    "- If yes, then chances of OOD data cases are high. \n",
    "- Do you want to think about the next archietcture?\n",
    "\n",
    "Practical Questions : \n",
    "- Can it work with never seen scenarios? What is your OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0297f",
   "metadata": {},
   "source": [
    "### What are OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b4cf6",
   "metadata": {},
   "source": [
    "OOD for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e556f8",
   "metadata": {},
   "source": [
    "![Lagrangian Example](figTeaser1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83434890",
   "metadata": {},
   "source": [
    "OOD for addition\n",
    "- Trained on numbers up to 100 \n",
    "- Test it on numbers beyond 100 \n",
    "\n",
    "OOD for Lagrangians\n",
    "- Trained on Lagrangians with 6 Fields\n",
    "- Test it on Lagrangians beyond 6 Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74d553",
   "metadata": {},
   "source": [
    "### N field Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a873438d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55da998",
   "metadata": {},
   "source": [
    "# Acknowledge SUPR\n",
    "The computations and data handling were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS) from projects NAISS 2025/22-521, partially funded by the Swedish Research Council through grant agreement no. 2022-06725"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
