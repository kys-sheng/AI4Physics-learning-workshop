{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d369682e",
   "metadata": {},
   "source": [
    "# <u>**Tackling a Realistic Physics Problem : How to approach it? What needs to be considered?**</u>\n",
    "<h4>\n",
    "<u>Content</u>: <br> \n",
    "0. Introducing our physics Example : Lagrangian Generation <br>\n",
    "1. Datasets : Distributions and Tokenization <br>\n",
    "2. Training : Where to find resources!<br>\n",
    "3. Evaluations : Metric vs Score, Embedding Analysis, Out-Of-Domain Generalization<br>\n",
    "</h4>\n",
    "\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f6a62",
   "metadata": {},
   "source": [
    "# 0. **Physics Example : Lagrangian Generation!**\n",
    "\n",
    "### **<u>Model Task</u>**\n",
    "<img src=\"https://i.imgur.com/dGfUOPB.png\" alt=\"Distribtuion\" width=\"900\">\n",
    "\n",
    "Reference: https://arxiv.org/abs/2501.09729\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66de86d",
   "metadata": {},
   "source": [
    "### **<u>Inference</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8888cf75",
   "metadata": {},
   "source": [
    "Before anything else, load some basic libraries :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec316c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if youre doing via google collab\n",
    "#!git clone https://github.com/kys-sheng/AI4Physics-learning-workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447fd8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this if youre doing via google collab\n",
    "# import sys\n",
    "# sys.path.append('/content/AI4Physics-learning-workshop')  # Adjust path as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f1910233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05b2961e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Youre using:  cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Youre using: \",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ec094",
   "metadata": {},
   "source": [
    "#### Load our model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "964c4027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/koay/Alvis/venv/jammymod/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name   = \"JoseEliel/BART-Lagrangian\"\n",
    "model        = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d56f7f",
   "metadata": {},
   "source": [
    "#### Lets write a Higgs-only Lagrangian with BART-L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4e34e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 0 SU2 2 U1 1 [EOS]\n",
      "token_id =  [0, 22, 36, 9, 37, 6, 39, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "higgs           = \"FIELD SPIN 0 SU2 2 U1 1\"\n",
    "    \n",
    "example_input   = \"[SOS] \"+higgs+\" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "\n",
    "encoded_input   = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d1d98",
   "metadata": {},
   "source": [
    "#### Generate the Lagrangian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0586ae74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : \n",
      "+ FIELD SPIN 0 SU2 2 U1 1 ID4 FIELD SPIN 0 SU2 2 U1 1 ID7 FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID0 FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID9 CONTRACTIONS SU2 ID4 ID0 SU2 ID7 ID9\n",
      "+ FIELD SPIN 0 SU2 2 U1 1 ID6 FIELD SPIN 0 SU2 2 U1 1 ID4 FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID2 FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID0 CONTRACTIONS SU2 ID6 ID4 SU2 ID2 ID0\n",
      "+ DERIVATIVE SU2 U1 ID6 FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID7 DERIVATIVE SU2 U1 ID0 FIELD SPIN 0 SU2 2 U1 1 ID4 CONTRACTIONS LORENTZ ID6 ID0 SU2 ID7 ID4\n",
      "- COMMUTATOR_A DERIVATIVE SU2 ID6 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID1 CONTRACTIONS LORENTZ ID6 ID4 LORENTZ ID0 ID1\n",
      "- COMMUTATOR_A DERIVATIVE U1 ID6 COMMUTATOR_B DERIVATIVE U1 ID0 COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID1 CONTRACTIONS LORENTZ ID6 ID4 LORENTZ ID0 ID1\n",
      "+ FIELD SPIN 0 SU2 2 U1 - 1 DAGGER ID6 FIELD SPIN 0 SU2 2 U1 1 ID7 CONTRACTIONS SU2 ID6 ID7\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate the ids for the Lagrangians\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0).to(device), max_length=1024)\n",
    "    # Decode it!\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0].to(device), skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted : \", )\n",
    "for i in le.sep_terms(predicted_string):\n",
    "    print(\" \".join(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63675859",
   "metadata": {},
   "source": [
    "An example of a translation table:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bfa6e",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/qD94qCd.png\" alt=\"Distribtuion\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc20997",
   "metadata": {},
   "source": [
    "## For a more interactive latex version of our model, see : https://huggingface.co/spaces/JoseEliel/generate-lagrangians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984e784e",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6bf30",
   "metadata": {},
   "source": [
    "<h1>\n",
    "Now comes the important parts, if you wanna start your project :  <br>\n",
    "<h2>\n",
    " - How to approach it?  <br>\n",
    " - What needs to be considered? <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dbe884",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4dc9c",
   "metadata": {},
   "source": [
    "# 1. **Preparing your Dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eccef88",
   "metadata": {},
   "source": [
    "<h2> Main point : NN are good interpolators, but not that good of an extrapolator. (Recall Niklas' talk) </h2> \n",
    "<h4>\n",
    "- NN learns from data. <br>\n",
    "- If the model is given something it has never seen, it figure outs based on existing experience  <br>\n",
    "- Training Data Distribution matters! <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a3ae47",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f836574f",
   "metadata": {},
   "source": [
    "# **1a. Data Distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8972275e",
   "metadata": {},
   "source": [
    "<h4>\n",
    "What do you need to think about? Where to start?    <br>\n",
    "\n",
    "**Rule of Thumb** : Think of your use case, and go from there!  <br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a605ef",
   "metadata": {},
   "source": [
    "## Example in Math  : x + y => ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4508ff36",
   "metadata": {},
   "source": [
    "### Use case :\n",
    "<div align=\"center\">\n",
    "     <h4> add any two numbers independent of the number's digits, <br> be it between 1-digit numbers (2+2) or 5-digit numbers (20000+16378) or something in between (42+2025)</h4>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1018bbe4",
   "metadata": {},
   "source": [
    "### So, Lets have a look at the digits of our numbers in the datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cb3b9d",
   "metadata": {},
   "source": [
    "Let's generate numbers from 1-10000 and do addition as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "36f0771e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 6521 + 9677 = 16198\n",
      "Example: 6288 + 6607 = 12895\n",
      "Example: 7572 + 1581 = 9153\n"
     ]
    }
   ],
   "source": [
    "num_examples = 10000\n",
    "min_num      = 1\n",
    "max_num      = 10000\n",
    "\n",
    "# Generate random examples\n",
    "examples     = [(random.randint(min_num, max_num),random.randint(min_num, max_num)) for _ in range(num_examples)]\n",
    "df           = pd.DataFrame(examples, columns=['x', 'y'])\n",
    "df['sum']    = df['x'] + df['y']\n",
    "\n",
    "print(f\"Example: {df['x'].iloc[0]} + { df['y'].iloc[0]} = { df['sum'].iloc[0]}\")\n",
    "print(f\"Example: {df['x'].iloc[1]} + { df['y'].iloc[1]} = { df['sum'].iloc[1]}\")\n",
    "print(f\"Example: {df['x'].iloc[2]} + { df['y'].iloc[2]} = { df['sum'].iloc[2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "62511348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Lets compute the number of digits in each number\n",
    "df['x_digit']   = df['x'].apply(lambda x: len(str(x)))    \n",
    "df['y_digit']   = df['y'].apply(lambda x: len(str(x)))    \n",
    "df['sum_digit'] = df['sum'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Plot the distribution of number of digits\n",
    "df['x_digit'].hist(label=\"x\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['y_digit'].hist(label=\"y\",range=(1,6),bins=5,alpha=0.5)\n",
    "df['sum_digit'].hist(label=\"sum\",range=(1,6),bins=5,alpha=0.5)\n",
    "plt.legend()\n",
    "plt.title(\"Distribution of number of digits\")\n",
    "plt.xlabel(\"Number of digits\")  \n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f96d97",
   "metadata": {},
   "source": [
    "### Probability of the model learning addition with **both numbers** having 1 digit, 2 digits, 3 digits, 4 digits, ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b10943d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(both_digit=1) =  0.0\n",
      "P(both_digit=2) =  0.0001\n",
      "P(both_digit=3) =  0.0086\n",
      "P(both_digit=4) =  0.8109\n",
      "P(both_digit=5) =  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"P(both_digit=1) = \", len(df[(df[\"x_digit\"] == 1) & (df[\"y_digit\"] == 1)]) / num_examples)\n",
    "print(\"P(both_digit=2) = \", len(df[(df[\"x_digit\"] == 2) & (df[\"y_digit\"] == 2)]) / num_examples)\n",
    "print(\"P(both_digit=3) = \", len(df[(df[\"x_digit\"] == 3) & (df[\"y_digit\"] == 3)]) / num_examples)\n",
    "print(\"P(both_digit=4) = \", len(df[(df[\"x_digit\"] == 4) & (df[\"y_digit\"] == 4)]) / num_examples)\n",
    "print(\"P(both_digit=5) = \", len(df[(df[\"x_digit\"] == 5) & (df[\"y_digit\"] == 5)]) / num_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed07424",
   "metadata": {},
   "source": [
    "### Probability of the model learning addition that gives a sum with 1 digit, 2 digits, 3 digits, 4 digits, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1498d509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(sum_digit=1) =  0.0\n",
      "P(sum_digit=2) =  0.0001\n",
      "P(sum_digit=3) =  0.0053\n",
      "P(sum_digit=4) =  0.4993\n",
      "P(sum_digit=5) =  0.4953\n"
     ]
    }
   ],
   "source": [
    "print(\"P(sum_digit=1) = \", len(df[df[\"sum_digit\"] == 1]) / num_examples)\n",
    "print(\"P(sum_digit=2) = \", len(df[df[\"sum_digit\"] == 2]) / num_examples)\n",
    "print(\"P(sum_digit=3) = \", len(df[df[\"sum_digit\"] == 3]) / num_examples)\n",
    "print(\"P(sum_digit=4) = \", len(df[df[\"sum_digit\"] == 4]) / num_examples)\n",
    "print(\"P(sum_digit=5) = \", len(df[df[\"sum_digit\"] == 5]) / num_examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82add299",
   "metadata": {},
   "source": [
    "### What you should do then in this case? \n",
    "- Oversample the low-digit cases! : \n",
    "    - They showed how Data Distribution affects GCD use-case\n",
    "    - https://arxiv.org/pdf/2308.15594 \n",
    "- Architectural choices          : \n",
    "    - introduce Continuous Numerical Tokenization [Treat numbers as numbers instead of alphabet like]\n",
    "    - https://arxiv.org/abs/2310.02989 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763f204f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2eeb50",
   "metadata": {},
   "source": [
    "## Example in Lagrangian Generation\n",
    "<div align=\"center\">\n",
    "     <h2> A , B, C -> L(A,B,C) </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4b481",
   "metadata": {},
   "source": [
    "### Use Case : \n",
    "A. Want to work with different number of fields : A,B,C,D,E,F <br>\n",
    "B. Want work with varying interactions : Quartic, Yukawa, Trilinears<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc59d80",
   "metadata": {},
   "source": [
    "### We generated two datasets to look into this: \n",
    "- Uniform Distribution : Randomly Generated <br>\n",
    "<img src=\"https://i.imgur.com/s4MJA9v.png\" alt=\"Distribtuion\" width=\"500\"><br>\n",
    "\n",
    "- Sampled Distribution : More trilinears (harder to get if randomly sample) but less large number of fields (Train Set Priming) <br>    \n",
    "<img src=\"https://i.imgur.com/K7p8fLR.png\" alt=\"Distribtuion\" width=\"500\"><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a442f",
   "metadata": {},
   "source": [
    "Reference : Train set priming https://arxiv.org/abs/2306.15400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c7aa2",
   "metadata": {},
   "source": [
    "# Takeaway: Build your data around your use case!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032383a",
   "metadata": {},
   "source": [
    "# **1b. Tokenization choices** : How detail should your tokenization be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0833bf0",
   "metadata": {},
   "source": [
    "In Language:\n",
    "Example Phrase : AI For Physics\n",
    "- Word-Level : AI, For, Physics\n",
    "- Character-Level : A, I,  , F, o, r,  , P, h, y, s, i, c, s\n",
    "\n",
    "In Math:\n",
    "Example Expression : 100 + 420 = 520\n",
    "- \"Term\"-level : 100, +, 420, =, 520\n",
    "- \"Digit\"-Level : 1, 0, 0,  +,  4, 2, 0, =,  5, 2, 0\n",
    "\n",
    "In Lagrangians:\n",
    "Example Field : Higgs Particle\n",
    "- Symbol Level : H\n",
    "- Quantum-Numbers-Level: FIELD, SPIN, 0, SU2, 2, U1, 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c97565",
   "metadata": {},
   "source": [
    "You can already see from these examples that the number of tokens changes! Any consequences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38e624",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb88417b",
   "metadata": {},
   "source": [
    "## Vocab Size vs Number of Tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f9a16",
   "metadata": {},
   "source": [
    "### Math Example : Tokenizing Numbers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4674bd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_level_example     :  8 9 8 5 8 + 8 2 2 = 9 0 6 8 0\n",
      "digit_level_example     :  1 4 6 8 7 + 7 9 1 5 1 = 9 3 8 3 8\n",
      "digit_level_example     :  9 4 7 9 5 + 9 9 6 7 3 = 1 9 4 4 6 8\n",
      "\n",
      "term_level_example     :  15683 + 7672 = 23355\n",
      "term_level_example     :  14223 + 97146 = 111369\n",
      "term_level_example     :  33603 + 50938 = 84541\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "# Character-level \n",
    "# 1. Generate arithmetic corpus as before\n",
    "num_examples = 10000\n",
    "min_num      = 0\n",
    "max_num      = 100000\n",
    "examples     = [(random.randint(min_num, max_num),random.randint(min_num, max_num)) for _ in range(num_examples)]\n",
    "digit_level_corpus = [\" \".join(list(f\"{a}+{b}={str(a + b)}\")) for a , b in examples]\n",
    "vocab = {\"1\" : 1, \"2\" : 2, \"3\" : 3, \"4\" : 4, \"5\" : 5, \"6\" : 6, \"7\" : 7, \"8\" : 8, \"9\" : 9,\n",
    "         \"0\" : 0, \"+\" : 10, \"=\" : 11,\"[UNK]\" : 12, \"[PAD]\" : 13, \"[BOS]\" : 14, \"[EOS]\" : 15}\n",
    "         \n",
    "# 2. Initialize tokenizer components\n",
    "digit_level_tokenizer = Tokenizer(WordLevel(vocab=vocab, unk_token=\"[UNK]\"))\n",
    "digit_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "# Word-level \n",
    "term_level_corpus = [f\"{a} + {b} = {str(a + b)}\" for a , b in examples]\n",
    "term_level_corpus.append(\"1 + 0 = 1\")\n",
    "term_level_tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "term_level_tokenizer.pre_tokenizer = Whitespace()\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    "trainer = WordLevelTrainer(special_tokens=special_tokens)\n",
    "term_level_tokenizer.train_from_iterator(term_level_corpus, trainer)\n",
    "\n",
    "for i in range(3):\n",
    "    digit_level_example = random.choice(digit_level_corpus)\n",
    "    print(\"digit_level_example     : \",digit_level_example)\n",
    "\n",
    "print()\n",
    "for i in range(3):\n",
    "    term_level_example = random.choice(term_level_corpus)\n",
    "    print(\"term_level_example     : \",term_level_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6c3bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_level_tokens      :  ['7', '2', '6', '6', '9', '+', '6', '8', '8', '1', '5', '=', '1', '4', '1', '4', '8', '4']\n",
      "digit_level_Ntokens     :  18\n",
      "digit_level_vocab_size  :  16\n",
      "\n",
      "term_level_tokens      :  ['19325', '+', '42108', '=', '61433']\n",
      "term_level_Ntokens     :  5\n",
      "term_level_vocab_size  :  26946\n"
     ]
    }
   ],
   "source": [
    "digit_level_example = random.choice(digit_level_corpus)\n",
    "print(\"digit_level_tokens      : \",digit_level_tokenizer.encode(digit_level_example).tokens)\n",
    "print(\"digit_level_Ntokens     : \",len(digit_level_tokenizer.encode(digit_level_example).tokens))\n",
    "print(\"digit_level_vocab_size  : \",digit_level_tokenizer.get_vocab_size(),end=\"\\n\\n\")\n",
    "\n",
    "term_level_example = random.choice(term_level_corpus)\n",
    "print(\"term_level_tokens      : \",term_level_tokenizer.encode(term_level_example).tokens)\n",
    "print(\"term_level_Ntokens     : \",len(term_level_tokenizer.encode(term_level_example).tokens))\n",
    "print(\"term_level_vocab_size  : \",term_level_tokenizer.get_vocab_size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c63028",
   "metadata": {},
   "source": [
    "char_level/digit_level : less vocabulary <br>\n",
    "word_level/term_level  : less tokens <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2813a1c1",
   "metadata": {},
   "source": [
    "### Lagrangian Example : Higgs-Only Lagrangian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "72be814b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lagrangian_tokens                       :  ['+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID8', 'CONTRACTIONS', 'SU3', 'ID7', 'ID6', 'ID0', 'SU3', 'ID6', 'ID0', 'ID8', 'SU2', 'ID7', 'ID6', 'SU2', 'ID7', 'ID6', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID4', 'CONTRACTIONS', 'SU3', 'ID7', 'ID6', 'ID6', 'SU3', 'ID0', 'ID0', 'ID4', 'SU2', 'ID7', 'ID6', 'SU2', 'ID7', 'ID6', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID1', 'CONTRACTIONS', 'SU3', 'ID7', 'ID0', 'ID0', 'SU3', 'ID6', 'ID1', 'ID1', 'SU2', 'ID7', 'ID0', 'SU2', 'ID7', 'ID0', 'SU2', 'ID6', 'ID1', 'SU2', 'ID6', 'ID1', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID4', 'CONTRACTIONS', 'SU3', 'ID7', 'ID0', 'ID0', 'SU3', 'ID6', 'ID4', 'ID4', 'SU2', 'ID7', 'ID6', 'SU2', 'ID7', 'ID0', 'SU2', 'ID6', 'ID4', 'SU2', 'ID0', 'ID4', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID1', 'CONTRACTIONS', 'SU3', 'ID7', 'ID0', 'ID0', 'SU3', 'ID6', 'ID1', 'ID1', 'SU2', 'ID7', 'ID6', 'SU2', 'ID7', 'ID6', 'SU2', 'ID0', 'ID1', 'SU2', 'ID0', 'ID1', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID9', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID8', 'CONTRACTIONS', 'SU3', 'ID7', 'ID0', 'ID9', 'SU3', 'ID9', 'ID8', 'ID8', 'SU2', 'ID7', 'ID9', 'SU2', 'ID7', 'ID9', 'SU2', 'ID0', 'ID8', 'SU2', 'ID0', 'ID8', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID1', 'CONTRACTIONS', 'SU3', 'ID7', 'ID6', 'ID0', 'SU3', 'ID0', 'ID1', 'ID1', 'SU2', 'ID7', 'ID6', 'SU2', 'ID7', 'ID0', 'SU2', 'ID6', 'ID1', 'SU2', 'ID0', 'ID1', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID1', 'CONTRACTIONS', 'SU3', 'ID6', 'ID7', 'ID0', 'SU3', 'ID0', 'ID1', 'ID1', 'SU2', 'ID6', 'ID7', 'SU2', 'ID6', 'ID7', 'SU2', 'ID0', 'ID1', 'SU2', 'ID0', 'ID1', '+', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID0', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID4', 'CONTRACTIONS', 'SU3', 'ID6', 'ID6', 'ID0', 'SU3', 'ID7', 'ID7', 'ID4', '+', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID4', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID0', 'CONTRACTIONS', 'SU3', 'ID7', 'ID7', 'ID4', 'SU3', 'ID4', 'ID6', 'ID0', '+', 'DERIVATIVE', 'SU3', 'SU2', 'U1', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID0', 'DERIVATIVE', 'SU3', 'SU2', 'U1', 'ID9', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'CONTRACTIONS', 'LORENTZ', 'ID7', 'ID9', 'SU3', 'ID0', 'ID6', 'SU2', 'ID0', 'ID6', '+', 'DERIVATIVE', 'SU3', 'U1', 'ID4', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID8', 'DERIVATIVE', 'SU3', 'U1', 'ID6', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID5', 'CONTRACTIONS', 'LORENTZ', 'ID4', 'ID6', 'SU3', 'ID8', 'ID5', '-', 'COMMUTATOR_A', 'DERIVATIVE', 'SU3', 'ID4', 'COMMUTATOR_B', 'DERIVATIVE', 'SU3', 'ID8', 'COMMUTATOR_A', 'DERIVATIVE', 'SU3', 'ID6', 'COMMUTATOR_B', 'DERIVATIVE', 'SU3', 'ID5', 'CONTRACTIONS', 'LORENTZ', 'ID4', 'ID6', 'LORENTZ', 'ID8', 'ID5', '-', 'COMMUTATOR_A', 'DERIVATIVE', 'SU2', 'ID6', 'COMMUTATOR_B', 'DERIVATIVE', 'SU2', 'ID7', 'COMMUTATOR_A', 'DERIVATIVE', 'SU2', 'ID0', 'COMMUTATOR_B', 'DERIVATIVE', 'SU2', 'ID4', 'CONTRACTIONS', 'LORENTZ', 'ID6', 'ID0', 'LORENTZ', 'ID7', 'ID4', '-', 'COMMUTATOR_A', 'DERIVATIVE', 'U1', 'ID7', 'COMMUTATOR_B', 'DERIVATIVE', 'U1', 'ID0', 'COMMUTATOR_A', 'DERIVATIVE', 'U1', 'ID6', 'COMMUTATOR_B', 'DERIVATIVE', 'U1', 'ID8', 'CONTRACTIONS', 'LORENTZ', 'ID7', 'ID6', 'LORENTZ', 'ID0', 'ID8', '+', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'SU2', '3', 'U1', '-', '6', 'DAGGER', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '3', 'SU2', '3', 'U1', '6', 'ID6', 'CONTRACTIONS', 'SU3', 'ID7', 'ID6', 'SU2', 'ID7', 'ID6', '+', 'FIELD', 'SPIN', '0', 'SU3', '3', 'U1', '7', '/', '2', 'DAGGER', 'ID7', 'FIELD', 'SPIN', '0', 'SU3', '-', '3', 'U1', '-', '7', '/', '2', 'ID6', 'CONTRACTIONS', 'SU3', 'ID7', 'ID6']\n",
      "Ntokens                                 :  858\n",
      "Vocabulary size                         :  41\n"
     ]
    }
   ],
   "source": [
    "example_fields  = \"FIELD SPIN 0 SU3 3 SU2 3 U1 6 FIELD SPIN 0 SU3 - 3 U1 - 7 / 2 \"\n",
    "example_input   = \"[SOS] \"+example_fields+\" [EOS]\"\n",
    "encoded_input   = hf_tokenizer.encode(example_input)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Generate the ids for the Lagrangians\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0).to(device), max_length=1024)\n",
    "    # Decode it!\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0].to(device), skip_special_tokens=True)\n",
    "\n",
    "print(\"Lagrangian_tokens                       : \",predicted_string.split())\n",
    "print(\"Ntokens                                 : \",len(predicted_string.split()))\n",
    "print(\"Vocabulary size                         : \", hf_tokenizer.vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d71f8b9",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/qD94qCd.png\" alt=\"Distribtuion\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f0e407",
   "metadata": {},
   "source": [
    "## Is your tokenization method expressive enough to go beyond training data? (OOD Considerations)\n",
    "### Math Example : Encoding 1000000000 [Your dataset were from 0 to 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7c1c2662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit_level_tokens                :  ['1', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "\n",
      "term_level_tokens                :  ['[UNK]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "OOD_digit_level_example =   \"1 0 0 0 0 0 0 0 0 0\"\n",
    "print(\"digit_level_tokens                : \",digit_level_tokenizer.encode(OOD_digit_level_example).tokens,end=\"\\n\\n\")\n",
    "\n",
    "OOD_term_level_example =   \"1000000000\"\n",
    "print(\"term_level_tokens                : \",term_level_tokenizer.encode(OOD_term_level_example).tokens,end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026ebca",
   "metadata": {},
   "source": [
    "since the word level tokenizer have never seen this number, it cant work with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "71261f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term_level_tokens (work-around)  :  ['1', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Something like this is possible but not intuitive (terms and number are slightly different)\n",
    "print(\"term_level_tokens (work-around)  : \",term_level_tokenizer.encode(OOD_char_level_example).tokens,end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0c2b2",
   "metadata": {},
   "source": [
    " There are work arounds, but then your model have never seen two numbers side by side, surely then it wont have a good idea of what it means. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc326d7",
   "metadata": {},
   "source": [
    "char_level/digit_level : more expressive and allows OOD generalization <br>\n",
    "word_level/term_level  : less expressive and need to think of workarounds (less intuitive) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c66ea2",
   "metadata": {},
   "source": [
    "# Takeaway :  Give and take between N_tokens and Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56797d2f",
   "metadata": {},
   "source": [
    "### 1. Detailed tokenization : \n",
    "- less vocabulary -> - more expressive\n",
    "- more token per sequence -> heavy on attention mechanism\n",
    "### 2. Coarse tokenization : \n",
    "- more vocabulary -> less expressive\n",
    "- less token per sequence -> easier on attention mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4575241a",
   "metadata": {},
   "source": [
    "## **Other Considerations:**\n",
    "### A. What information is relevant/interesting for your model to learn?\n",
    "#### Lagrangian Example: Covariant Derivatives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108f420b",
   "metadata": {},
   "source": [
    "In some case, we need to be creative : Covariant Derivatives are everywhere, Kinetic terms can be written with Derivatives, ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3dadb",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/2yGqCVT.png\" alt=\"Distribtuion\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f152260",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# 2. **Training** : Where to find resources?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d5a3b8",
   "metadata": {},
   "source": [
    "### NAISS : https://www.naiss.se/\n",
    "- Provider of compute and storage resources\n",
    "- For any researchers based in Sweden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfdeb40",
   "metadata": {},
   "source": [
    "\n",
    "### SUPR : https://supr.naiss.se/\n",
    "- Portal to apply for it. \n",
    "- There are varyind levels of applications [small, medium, large]\n",
    "- PhD students and above can already apply for small compute (Alvis: 1000GPUhs/months and Dardel: 20000 CPU-h/month!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055dafdc",
   "metadata": {},
   "source": [
    "\n",
    "### For GPU, we recommend:\n",
    "#### Alvis : https://www.c3se.chalmers.se/about/Alvis/ <br> OnDemand Portal : https://alvis.c3se.chalmers.se/pun/sys/dashboard/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b926aecc",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9823e0",
   "metadata": {},
   "source": [
    "# 3. **Evaluation**\n",
    "\n",
    "<h2>\n",
    "To evaluate your model properly. <br>\n",
    "Rule of Thumb : Again , think of your use case!\n",
    "</h2>\n",
    "\n",
    "------ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a65c22",
   "metadata": {},
   "source": [
    "\n",
    "<h2>\n",
    "<u>A. Is Cross-Entropy Loss enough for your problem?</u>  (Think about permutation invariance, conservation laws, ...)\n",
    "<h4>\n",
    "  <ul>\n",
    "    <li> Yes? -> Ignore. </li>\n",
    "    <li> No? -> <b><u>Create your own metric</b></u> : See 3A</li>\n",
    "  </ul>\n",
    "</h4>\n",
    "\n",
    "<h3>\n",
    "For example, we define Lagrangian Score as:\n",
    "<div align=\"center\">\n",
    "     <h4> S_Lagrangian = (N_correct - N_Extra) / N_true </h3>\n",
    "</div>\n",
    "\n",
    "where:\n",
    "- N_correct = Number of correct terms\n",
    "- N_Extra = Number of extra terms\n",
    "- N_true = True Number of terms \n",
    "\n",
    "------ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4585f420",
   "metadata": {},
   "source": [
    "<h2>\n",
    "B. Do you care whether the model internalizes the right concepts? (Relationship between symbols, or between inputs and outputs) \n",
    "<h4>\n",
    "  <ul>\n",
    "    <li> Yes? -> <b><u>Embedding Analysis</b></u> : See 3B</li> \n",
    "    <li> No? -> Continue </li>\n",
    "  </ul>\n",
    "\n",
    "<h3>\n",
    "For example, did the model learned symmetry group and representations (Lorentz, SU3, SU2, U1)? Yes! <br>\n",
    "<img src=\"https://i.imgur.com/ycNegGp.png\" alt=\"Embeddings in LLM\" width=\"500\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9de09d4",
   "metadata": {},
   "source": [
    "<h2>\n",
    "C. Is your problem \"infinite\"(ie probability of getting an unseen data point is high)?  \n",
    "<h4>\n",
    "  <ul>\n",
    "    <li>Yes? -> <b><u>OoD Generalization</b></u> : See 3C </li>\n",
    "    <li>No? -> Continue </li>\n",
    "  </ul>\n",
    "\n",
    "<h3>\n",
    "For example, can we go beyond 6 fields? <br>\n",
    "<img src=\"https://i.imgur.com/yzdcPMB.png\" alt=\"Embeddings in LLM\" width=\"1000\">\n",
    "\n",
    "OOD Task can also lead to insights on the architectural constraints on task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeab7ed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6b2ab6",
   "metadata": {},
   "source": [
    "# 3A. Existing Metric  : Does it work? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c788b83",
   "metadata": {},
   "source": [
    "mainly to see if things work as expected\n",
    "Loss : Deviation from actual term \n",
    "Accuracy : How much is perfect? \n",
    "New metric, Score : (Order does not always matter, XEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8de2039d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/koay/Alvis/venv/jammymod/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available\n",
    "import torch\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name   = \"JoseEliel/BART-Lagrangian\"\n",
    "model        = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25d150b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_dataset_sampled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf huggingface_dataset_sampled.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbe043a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data if not already loaded, drop duplicates\n",
    "sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "sampled_df.drop_duplicates(subset=[\"fields\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be1b2fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fields</th>\n",
       "      <th>Lagrangian</th>\n",
       "      <th>train/eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIELD SPIN 1/2 SU3 - 3 SU2 2 U1 - 4 HEL 1/2 FI...</td>\n",
       "      <td>+ FIELD SPIN 1 / 2 SU3 - 3 SU2 2 HEL - 1 / 2 D...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIELD SPIN 1/2 HEL 1/2 FIELD SPIN 1/2 SU3 - 3 ...</td>\n",
       "      <td>+ i FIELD SPIN 1 / 2 HEL 1 / 2 ID9 SIGMA_BAR I...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIELD SPIN 0 SU2 3 U1 - 4 / 9 FIELD SPIN 1/2 S...</td>\n",
       "      <td>+ FIELD SPIN 0 SU2 3 U1 - 4 / 9 ID1 FIELD SPIN...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIELD SPIN 1/2 SU3 - 3 U1 3 / 8 HEL -1/2 FIELD...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 8 / 9 ID3 FI...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 3 SU2 3 ID4 FIELD SPIN 0 SU...</td>\n",
       "      <td>eval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286076</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3 U1 9 / 2 FIELD SPIN 1...</td>\n",
       "      <td>+ FIELD SPIN 1 / 2 SU2 2 U1 1 / 5 HEL - 1 / 2 ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286077</th>\n",
       "      <td>FIELD SPIN 0 FIELD SPIN 0 SU3 3 SU2 3 U1 7 / 6...</td>\n",
       "      <td>+ FIELD SPIN 0 ID1 FIELD SPIN 0 SU3 3 SU2 3 U1...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286078</th>\n",
       "      <td>FIELD SPIN 0 SU3 - 3 U1 3 FIELD SPIN 1/2 SU3 3...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 U1 3 ID4 FIELD SPIN 0 S...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286079</th>\n",
       "      <td>FIELD SPIN 1/2 U1 - 4 / 5 HEL -1/2 FIELD SPIN ...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 1 / 7 ID6 FI...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286080</th>\n",
       "      <td>FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 FIELD SPIN 1/2...</td>\n",
       "      <td>+ FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 ID0 FIELD SP...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211283 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   fields  \\\n",
       "0       FIELD SPIN 1/2 SU3 - 3 SU2 2 U1 - 4 HEL 1/2 FI...   \n",
       "1       FIELD SPIN 1/2 HEL 1/2 FIELD SPIN 1/2 SU3 - 3 ...   \n",
       "2       FIELD SPIN 0 SU2 3 U1 - 4 / 9 FIELD SPIN 1/2 S...   \n",
       "3       FIELD SPIN 1/2 SU3 - 3 U1 3 / 8 HEL -1/2 FIELD...   \n",
       "4                                FIELD SPIN 0 SU3 3 SU2 3   \n",
       "...                                                   ...   \n",
       "286076  FIELD SPIN 0 SU3 3 SU2 3 U1 9 / 2 FIELD SPIN 1...   \n",
       "286077  FIELD SPIN 0 FIELD SPIN 0 SU3 3 SU2 3 U1 7 / 6...   \n",
       "286078  FIELD SPIN 0 SU3 - 3 U1 3 FIELD SPIN 1/2 SU3 3...   \n",
       "286079  FIELD SPIN 1/2 U1 - 4 / 5 HEL -1/2 FIELD SPIN ...   \n",
       "286080  FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 FIELD SPIN 1/2...   \n",
       "\n",
       "                                               Lagrangian train/eval  \n",
       "0       + FIELD SPIN 1 / 2 SU3 - 3 SU2 2 HEL - 1 / 2 D...       eval  \n",
       "1       + i FIELD SPIN 1 / 2 HEL 1 / 2 ID9 SIGMA_BAR I...       eval  \n",
       "2       + FIELD SPIN 0 SU2 3 U1 - 4 / 9 ID1 FIELD SPIN...       eval  \n",
       "3       + FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 8 / 9 ID3 FI...       eval  \n",
       "4       + FIELD SPIN 0 SU3 3 SU2 3 ID4 FIELD SPIN 0 SU...       eval  \n",
       "...                                                   ...        ...  \n",
       "286076  + FIELD SPIN 1 / 2 SU2 2 U1 1 / 5 HEL - 1 / 2 ...      train  \n",
       "286077  + FIELD SPIN 0 ID1 FIELD SPIN 0 SU3 3 SU2 3 U1...      train  \n",
       "286078  + FIELD SPIN 0 SU3 - 3 U1 3 ID4 FIELD SPIN 0 S...      train  \n",
       "286079  + FIELD SPIN 0 SU3 - 3 SU2 2 U1 - 1 / 7 ID6 FI...      train  \n",
       "286080  + FIELD SPIN 0 SU3 3 SU2 3 U1 - 1 ID0 FIELD SP...      train  \n",
       "\n",
       "[211283 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5498f",
   "metadata": {},
   "source": [
    "### Example : Lagrangian Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b01da",
   "metadata": {},
   "source": [
    "Choose a random lagrangian to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18376d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_scenario = sampled_df.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b709e360",
   "metadata": {},
   "source": [
    "Look at the input (field content) and the output (Lagrangian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c89747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 0 SU3 - 3 SU2 2 FIELD SPIN 0 FIELD SPIN 0 U1 9 [EOS]\n",
      "token_id =  [0, 22, 36, 9, 38, 7, 10, 37, 6, 22, 36, 9, 22, 36, 9, 39, 16, 1]\n",
      "decoded  =  [SOS] FIELD SPIN 0 SU3 - 3 SU2 2 FIELD SPIN 0 FIELD SPIN 0 U1 9 [EOS]\n",
      "\n",
      "Output   =  [SOS] + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3 + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 CONTRACTIONS SU3 ID2 ID2 ID3 SU3 ID0 ID0 ID6 SU2 ID2 ID3 SU2 ID0 ID6 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 CONTRACTIONS SU3 ID5 ID5 ID3 SU3 ID9 ID9 ID2 SU2 ID5 ID9 SU2 ID3 ID2 + FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 CONTRACTIONS SU3 ID0 ID0 ID6 SU3 ID6 ID7 ID8 SU2 ID0 ID7 SU2 ID6 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID5 ID5 ID7 SU3 ID7 ID8 ID9 SU2 ID5 ID7 SU2 ID8 ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID1 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID2 FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 + FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 9 ID1 FIELD SPIN 0 U1 - 9 DAGGER ID6 FIELD SPIN 0 U1 - 9 DAGGER ID0 + DERIVATIVE SU3 SU2 ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 DERIVATIVE SU3 SU2 ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID4 CONTRACTIONS LORENTZ ID1 ID9 SU3 ID3 ID4 SU2 ID3 ID4 + DERIVATIVE ID3 FIELD SPIN 0 DAGGER ID0 DERIVATIVE ID8 FIELD SPIN 0 ID7 CONTRACTIONS LORENTZ ID3 ID8 + DERIVATIVE U1 ID5 FIELD SPIN 0 U1 - 9 DAGGER ID3 DERIVATIVE U1 ID0 FIELD SPIN 0 U1 9 ID6 CONTRACTIONS LORENTZ ID5 ID0 - COMMUTATOR_A DERIVATIVE SU3 ID8 COMMUTATOR_B DERIVATIVE SU3 ID7 COMMUTATOR_A DERIVATIVE SU3 ID3 COMMUTATOR_B DERIVATIVE SU3 ID0 CONTRACTIONS LORENTZ ID8 ID3 LORENTZ ID7 ID0 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID3 CONTRACTIONS LORENTZ ID4 ID7 LORENTZ ID0 ID3 - COMMUTATOR_A DERIVATIVE U1 ID5 COMMUTATOR_B DERIVATIVE U1 ID7 COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID1 CONTRACTIONS LORENTZ ID5 ID4 LORENTZ ID7 ID1 + FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID2 CONTRACTIONS SU3 ID9 ID2 SU2 ID9 ID2 + FIELD SPIN 0 DAGGER ID6 FIELD SPIN 0 ID5 CONTRACTIONS + FIELD SPIN 0 U1 - 9 DAGGER ID7 FIELD SPIN 0 U1 9 ID2 CONTRACTIONS [EOS]\n",
      "token_id =  [0, 8, 22, 36, 9, 38, 7, 10, 37, 6, 26, 22, 36, 9, 38, 10, 37, 6, 20, 27, 22, 36, 9, 31, 19, 38, 26, 26, 27, 37, 26, 27, 8, 22, 36, 9, 30, 22, 36, 9, 39, 16, 31, 22, 36, 9, 39, 7, 16, 20, 33, 8, 22, 36, 9, 28, 22, 36, 9, 27, 22, 36, 9, 29, 8, 22, 36, 9, 38, 7, 10, 37, 6, 26, 22, 36, 9, 38, 10, 37, 6, 20, 32, 22, 36, 9, 31, 22, 36, 9, 25, 19, 38, 26, 26, 32, 37, 26, 32, 8, 22, 36, 9, 38, 7, 10, 37, 6, 33, 22, 36, 9, 38, 10, 37, 6, 20, 27, 22, 36, 9, 39, 16, 32, 22, 36, 9, 39, 7, 16, 20, 29, 19, 38, 33, 33, 27, 37, 33, 27, 8, 22, 36, 9, 38, 7, 10, 37, 6, 26, 22, 36, 9, 38, 7, 10, 37, 6, 24, 22, 36, 9, 38, 10, 37, 6, 20, 27, 22, 36, 9, 38, 10, 37, 6, 20, 30, 19, 38, 26, 26, 27, 38, 24, 24, 30, 37, 26, 27, 37, 24, 30, 8, 22, 36, 9, 38, 7, 10, 37, 6, 29, 22, 36, 9, 38, 7, 10, 37, 6, 33, 22, 36, 9, 38, 10, 37, 6, 20, 27, 22, 36, 9, 38, 10, 37, 6, 20, 26, 19, 38, 29, 29, 27, 38, 33, 33, 26, 37, 29, 33, 37, 27, 26, 8, 22, 36, 9, 38, 7, 10, 37, 6, 24, 22, 36, 9, 38, 7, 10, 37, 6, 30, 22, 36, 9, 38, 10, 37, 6, 20, 31, 22, 36, 9, 38, 10, 37, 6, 20, 32, 19, 38, 24, 24, 30, 38, 30, 31, 32, 37, 24, 31, 37, 30, 32, 8, 22, 36, 9, 38, 7, 10, 37, 6, 29, 22, 36, 9, 38, 7, 10, 37, 6, 31, 22, 36, 9, 38, 10, 37, 6, 20, 32, 22, 36, 9, 38, 10, 37, 6, 20, 33, 19, 38, 29, 29, 31, 38, 31, 32, 33, 37, 29, 31, 37, 32, 33, 8, 22, 36, 9, 28, 22, 36, 9, 29, 22, 36, 9, 39, 16, 32, 22, 36, 9, 39, 7, 16, 20, 25, 8, 22, 36, 9, 30, 22, 36, 9, 26, 22, 36, 9, 28, 22, 36, 9, 29, 8, 22, 36, 9, 39, 16, 31, 22, 36, 9, 39, 16, 25, 22, 36, 9, 39, 7, 16, 20, 30, 22, 36, 9, 39, 7, 16, 20, 24, 8, 21, 38, 37, 25, 22, 36, 9, 38, 10, 37, 6, 20, 27, 21, 38, 37, 33, 22, 36, 9, 38, 7, 10, 37, 6, 28, 19, 34, 25, 33, 38, 27, 28, 37, 27, 28, 8, 21, 27, 22, 36, 9, 20, 24, 21, 32, 22, 36, 9, 31, 19, 34, 27, 32, 8, 21, 39, 29, 22, 36, 9, 39, 7, 16, 20, 27, 21, 39, 24, 22, 36, 9, 39, 16, 30, 19, 34, 29, 24, 7, 17, 21, 38, 32, 18, 21, 38, 31, 17, 21, 38, 27, 18, 21, 38, 24, 19, 34, 32, 27, 34, 31, 24, 7, 17, 21, 37, 28, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 27, 19, 34, 28, 31, 34, 24, 27, 7, 17, 21, 39, 29, 18, 21, 39, 31, 17, 21, 39, 28, 18, 21, 39, 25, 19, 34, 29, 28, 34, 31, 25, 8, 22, 36, 9, 38, 10, 37, 6, 20, 33, 22, 36, 9, 38, 7, 10, 37, 6, 26, 19, 38, 33, 26, 37, 33, 26, 8, 22, 36, 9, 20, 30, 22, 36, 9, 29, 19, 8, 22, 36, 9, 39, 7, 16, 20, 31, 22, 36, 9, 39, 16, 26, 19, 1]\n",
      "decoded  =  [SOS] + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3 + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 CONTRACTIONS SU3 ID2 ID2 ID3 SU3 ID0 ID0 ID6 SU2 ID2 ID3 SU2 ID0 ID6 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 CONTRACTIONS SU3 ID5 ID5 ID3 SU3 ID9 ID9 ID2 SU2 ID5 ID9 SU2 ID3 ID2 + FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 CONTRACTIONS SU3 ID0 ID0 ID6 SU3 ID6 ID7 ID8 SU2 ID0 ID7 SU2 ID6 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID5 ID5 ID7 SU3 ID7 ID8 ID9 SU2 ID5 ID7 SU2 ID8 ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID1 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID2 FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 + FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 9 ID1 FIELD SPIN 0 U1 - 9 DAGGER ID6 FIELD SPIN 0 U1 - 9 DAGGER ID0 + DERIVATIVE SU3 SU2 ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 DERIVATIVE SU3 SU2 ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID4 CONTRACTIONS LORENTZ ID1 ID9 SU3 ID3 ID4 SU2 ID3 ID4 + DERIVATIVE ID3 FIELD SPIN 0 DAGGER ID0 DERIVATIVE ID8 FIELD SPIN 0 ID7 CONTRACTIONS LORENTZ ID3 ID8 + DERIVATIVE U1 ID5 FIELD SPIN 0 U1 - 9 DAGGER ID3 DERIVATIVE U1 ID0 FIELD SPIN 0 U1 9 ID6 CONTRACTIONS LORENTZ ID5 ID0 - COMMUTATOR_A DERIVATIVE SU3 ID8 COMMUTATOR_B DERIVATIVE SU3 ID7 COMMUTATOR_A DERIVATIVE SU3 ID3 COMMUTATOR_B DERIVATIVE SU3 ID0 CONTRACTIONS LORENTZ ID8 ID3 LORENTZ ID7 ID0 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID3 CONTRACTIONS LORENTZ ID4 ID7 LORENTZ ID0 ID3 - COMMUTATOR_A DERIVATIVE U1 ID5 COMMUTATOR_B DERIVATIVE U1 ID7 COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID1 CONTRACTIONS LORENTZ ID5 ID4 LORENTZ ID7 ID1 + FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID2 CONTRACTIONS SU3 ID9 ID2 SU2 ID9 ID2 + FIELD SPIN 0 DAGGER ID6 FIELD SPIN 0 ID5 CONTRACTIONS + FIELD SPIN 0 U1 - 9 DAGGER ID7 FIELD SPIN 0 U1 9 ID2 CONTRACTIONS [EOS]\n"
     ]
    }
   ],
   "source": [
    "example = example_scenario[\"fields\"].values[0]\n",
    "example_input = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n",
    "print()\n",
    "example = example_scenario[\"Lagrangian\"].values[0]\n",
    "example_output = \"[SOS] \" + example + \" [EOS]\"\n",
    "print(\"Output   = \",example_output)\n",
    "encoded_output = hf_tokenizer.encode(example_output)\n",
    "print(\"token_id = \", encoded_output)\n",
    "decoded_output = hf_tokenizer.decode(encoded_output)\n",
    "print(\"decoded  = \", decoded_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc9f9",
   "metadata": {},
   "source": [
    "Look at the output (Lagrangian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e8dc620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five terms: \n",
      "term 1 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3\n",
      "term 2 :  + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9\n",
      "term 3 :  + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5\n",
      "term 4 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8\n",
      "term 5 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3\n"
     ]
    }
   ],
   "source": [
    "# show the terms \n",
    "separated_terms = le.sep_terms(decoded_output)\n",
    "\n",
    "print(\"First five terms: \")\n",
    "for i in range(len(separated_terms)):\n",
    "    if i>4: break\n",
    "    print(f\"term {i+1} : \",\" \".join(separated_terms[i]))\n",
    "    \n",
    "lag_truth_1 =  \" \".join([\" \".join(i) for i in separated_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd382b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First five terms after reordering: \n",
      "term 1 :  + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9\n",
      "term 2 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3\n",
      "term 3 :  + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5\n",
      "term 4 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8\n",
      "term 5 :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3\n"
     ]
    }
   ],
   "source": [
    "# reorder the first and second terms using list \n",
    "separated_terms[0],separated_terms[1] = separated_terms[1],separated_terms[0]\n",
    "\n",
    "print(\"First five terms after reordering: \")\n",
    "for i in range(len(separated_terms)):\n",
    "    if i>4: break\n",
    "    print(f\"term {i+1} : \",\" \".join(separated_terms[i]))\n",
    "lag_truth_2 =  \" \".join([\" \".join(i) for i in separated_terms])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa1e60b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " [0, 22, 36, 9, 38, 7, 10, 37, 6, 22, 36, 9, 22, 36, 9, 39, 16, 1]\n",
      "\n",
      "Outputs:\n",
      "labels_1:  tensor([[ 0,  8, 22, 36,  9, 38,  7, 10, 37,  6, 26, 22, 36,  9, 38, 10, 37,  6,\n",
      "         20, 27, 22, 36,  9, 31, 19, 38, 26, 26, 27, 37, 26, 27,  8, 22, 36,  9,\n",
      "         30, 22, 36,  9, 39, 16, 31, 22, 36,  9, 39,  7, 16, 20, 33,  8, 22, 36,\n",
      "          9, 28, 22, 36,  9, 27, 22, 36,  9, 29,  8, 22, 36,  9, 38,  7, 10, 37,\n",
      "          6, 26, 22, 36,  9, 38, 10, 37,  6, 20, 32, 22, 36,  9, 31, 22, 36,  9,\n",
      "         25, 19, 38, 26, 26, 32, 37, 26, 32,  8, 22, 36,  9, 38,  7, 10, 37,  6,\n",
      "         33, 22, 36,  9, 38, 10, 37,  6, 20, 27, 22, 36,  9, 39, 16, 32, 22, 36,\n",
      "          9, 39,  7, 16, 20, 29, 19, 38, 33, 33, 27, 37, 33, 27,  8, 22, 36,  9,\n",
      "         38,  7, 10, 37,  6, 26, 22, 36,  9, 38,  7, 10, 37,  6, 24, 22, 36,  9,\n",
      "         38, 10, 37,  6, 20, 27, 22, 36,  9, 38, 10, 37,  6, 20, 30, 19, 38, 26,\n",
      "         26, 27, 38, 24, 24, 30, 37, 26, 27, 37, 24, 30,  8, 22, 36,  9, 38,  7,\n",
      "         10, 37,  6, 29, 22, 36,  9, 38,  7, 10, 37,  6, 33, 22, 36,  9, 38, 10,\n",
      "         37,  6, 20, 27, 22, 36,  9, 38, 10, 37,  6, 20, 26, 19, 38, 29, 29, 27,\n",
      "         38, 33, 33, 26, 37, 29, 33, 37, 27, 26,  8, 22, 36,  9, 38,  7, 10, 37,\n",
      "          6, 24, 22, 36,  9, 38,  7, 10, 37,  6, 30, 22, 36,  9, 38, 10, 37,  6,\n",
      "         20, 31, 22, 36,  9, 38, 10, 37,  6, 20, 32, 19, 38, 24, 24, 30, 38, 30,\n",
      "         31, 32, 37, 24, 31, 37, 30, 32,  8, 22, 36,  9, 38,  7, 10, 37,  6, 29,\n",
      "         22, 36,  9, 38,  7, 10, 37,  6, 31, 22, 36,  9, 38, 10, 37,  6, 20, 32,\n",
      "         22, 36,  9, 38, 10, 37,  6, 20, 33, 19, 38, 29, 29, 31, 38, 31, 32, 33,\n",
      "         37, 29, 31, 37, 32, 33,  8, 22, 36,  9, 28, 22, 36,  9, 29, 22, 36,  9,\n",
      "         39, 16, 32, 22, 36,  9, 39,  7, 16, 20, 25,  8, 22, 36,  9, 30, 22, 36,\n",
      "          9, 26, 22, 36,  9, 28, 22, 36,  9, 29,  8, 22, 36,  9, 39, 16, 31, 22,\n",
      "         36,  9, 39, 16, 25, 22, 36,  9, 39,  7, 16, 20, 30, 22, 36,  9, 39,  7,\n",
      "         16, 20, 24,  8, 21, 38, 37, 25, 22, 36,  9, 38, 10, 37,  6, 20, 27, 21,\n",
      "         38, 37, 33, 22, 36,  9, 38,  7, 10, 37,  6, 28, 19, 34, 25, 33, 38, 27,\n",
      "         28, 37, 27, 28,  8, 21, 27, 22, 36,  9, 20, 24, 21, 32, 22, 36,  9, 31,\n",
      "         19, 34, 27, 32,  8, 21, 39, 29, 22, 36,  9, 39,  7, 16, 20, 27, 21, 39,\n",
      "         24, 22, 36,  9, 39, 16, 30, 19, 34, 29, 24,  7, 17, 21, 38, 32, 18, 21,\n",
      "         38, 31, 17, 21, 38, 27, 18, 21, 38, 24, 19, 34, 32, 27, 34, 31, 24,  7,\n",
      "         17, 21, 37, 28, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 27, 19, 34,\n",
      "         28, 31, 34, 24, 27,  7, 17, 21, 39, 29, 18, 21, 39, 31, 17, 21, 39, 28,\n",
      "         18, 21, 39, 25, 19, 34, 29, 28, 34, 31, 25,  8, 22, 36,  9, 38, 10, 37,\n",
      "          6, 20, 33, 22, 36,  9, 38,  7, 10, 37,  6, 26, 19, 38, 33, 26, 37, 33,\n",
      "         26,  8, 22, 36,  9, 20, 30, 22, 36,  9, 29, 19,  8, 22, 36,  9, 39,  7,\n",
      "         16, 20, 31, 22, 36,  9, 39, 16, 26, 19,  1]], device='cuda:0')\n",
      "labels_2:  tensor([[ 0,  8, 22, 36,  9, 30, 22, 36,  9, 39, 16, 31, 22, 36,  9, 39,  7, 16,\n",
      "         20, 33,  8, 22, 36,  9, 38,  7, 10, 37,  6, 26, 22, 36,  9, 38, 10, 37,\n",
      "          6, 20, 27, 22, 36,  9, 31, 19, 38, 26, 26, 27, 37, 26, 27,  8, 22, 36,\n",
      "          9, 28, 22, 36,  9, 27, 22, 36,  9, 29,  8, 22, 36,  9, 38,  7, 10, 37,\n",
      "          6, 26, 22, 36,  9, 38, 10, 37,  6, 20, 32, 22, 36,  9, 31, 22, 36,  9,\n",
      "         25, 19, 38, 26, 26, 32, 37, 26, 32,  8, 22, 36,  9, 38,  7, 10, 37,  6,\n",
      "         33, 22, 36,  9, 38, 10, 37,  6, 20, 27, 22, 36,  9, 39, 16, 32, 22, 36,\n",
      "          9, 39,  7, 16, 20, 29, 19, 38, 33, 33, 27, 37, 33, 27,  8, 22, 36,  9,\n",
      "         38,  7, 10, 37,  6, 26, 22, 36,  9, 38,  7, 10, 37,  6, 24, 22, 36,  9,\n",
      "         38, 10, 37,  6, 20, 27, 22, 36,  9, 38, 10, 37,  6, 20, 30, 19, 38, 26,\n",
      "         26, 27, 38, 24, 24, 30, 37, 26, 27, 37, 24, 30,  8, 22, 36,  9, 38,  7,\n",
      "         10, 37,  6, 29, 22, 36,  9, 38,  7, 10, 37,  6, 33, 22, 36,  9, 38, 10,\n",
      "         37,  6, 20, 27, 22, 36,  9, 38, 10, 37,  6, 20, 26, 19, 38, 29, 29, 27,\n",
      "         38, 33, 33, 26, 37, 29, 33, 37, 27, 26,  8, 22, 36,  9, 38,  7, 10, 37,\n",
      "          6, 24, 22, 36,  9, 38,  7, 10, 37,  6, 30, 22, 36,  9, 38, 10, 37,  6,\n",
      "         20, 31, 22, 36,  9, 38, 10, 37,  6, 20, 32, 19, 38, 24, 24, 30, 38, 30,\n",
      "         31, 32, 37, 24, 31, 37, 30, 32,  8, 22, 36,  9, 38,  7, 10, 37,  6, 29,\n",
      "         22, 36,  9, 38,  7, 10, 37,  6, 31, 22, 36,  9, 38, 10, 37,  6, 20, 32,\n",
      "         22, 36,  9, 38, 10, 37,  6, 20, 33, 19, 38, 29, 29, 31, 38, 31, 32, 33,\n",
      "         37, 29, 31, 37, 32, 33,  8, 22, 36,  9, 28, 22, 36,  9, 29, 22, 36,  9,\n",
      "         39, 16, 32, 22, 36,  9, 39,  7, 16, 20, 25,  8, 22, 36,  9, 30, 22, 36,\n",
      "          9, 26, 22, 36,  9, 28, 22, 36,  9, 29,  8, 22, 36,  9, 39, 16, 31, 22,\n",
      "         36,  9, 39, 16, 25, 22, 36,  9, 39,  7, 16, 20, 30, 22, 36,  9, 39,  7,\n",
      "         16, 20, 24,  8, 21, 38, 37, 25, 22, 36,  9, 38, 10, 37,  6, 20, 27, 21,\n",
      "         38, 37, 33, 22, 36,  9, 38,  7, 10, 37,  6, 28, 19, 34, 25, 33, 38, 27,\n",
      "         28, 37, 27, 28,  8, 21, 27, 22, 36,  9, 20, 24, 21, 32, 22, 36,  9, 31,\n",
      "         19, 34, 27, 32,  8, 21, 39, 29, 22, 36,  9, 39,  7, 16, 20, 27, 21, 39,\n",
      "         24, 22, 36,  9, 39, 16, 30, 19, 34, 29, 24,  7, 17, 21, 38, 32, 18, 21,\n",
      "         38, 31, 17, 21, 38, 27, 18, 21, 38, 24, 19, 34, 32, 27, 34, 31, 24,  7,\n",
      "         17, 21, 37, 28, 18, 21, 37, 24, 17, 21, 37, 31, 18, 21, 37, 27, 19, 34,\n",
      "         28, 31, 34, 24, 27,  7, 17, 21, 39, 29, 18, 21, 39, 31, 17, 21, 39, 28,\n",
      "         18, 21, 39, 25, 19, 34, 29, 28, 34, 31, 25,  8, 22, 36,  9, 38, 10, 37,\n",
      "          6, 20, 33, 22, 36,  9, 38,  7, 10, 37,  6, 26, 19, 38, 33, 26, 37, 33,\n",
      "         26,  8, 22, 36,  9, 20, 30, 22, 36,  9, 29, 19,  8, 22, 36,  9, 39,  7,\n",
      "         16, 20, 31, 22, 36,  9, 39, 16, 26, 19,  1]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Inputs:\\n\", encoded_input)\n",
    "print()\n",
    "\n",
    "print(\"Outputs:\",)\n",
    "targets_1 = hf_tokenizer(\"[SOS] \" + lag_truth_1 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "targets_2 = hf_tokenizer(\"[SOS] \" + lag_truth_2 + \" [EOS]\", return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "\n",
    "#print(\"targets_1: \", targets_1)\n",
    "labels_1 = targets_1[\"input_ids\"]\n",
    "#print(\"targets_2: \", targets_2)\n",
    "labels_2 = targets_2[\"input_ids\"]\n",
    "\n",
    "\n",
    "#print(\"inputs: \", hf_tokenizer.decode(encoded_input))\n",
    "print(\"labels_1: \", labels_1)\n",
    "#print(\"labels_1: \", hf_tokenizer.decode(labels_1[0]))\n",
    "print(\"labels_2: \", labels_2)\n",
    "#print(\"labels_2: \", hf_tokenizer.decode(labels_2[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ffd64d",
   "metadata": {},
   "source": [
    "Generate the Lagrangians and calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07006038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss with labels_1: tensor(0.2585, device='cuda:0')\n",
      "loss with labels_2: tensor(0.3015, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # loss with labels_1 and labels_2\n",
    "    outputs_1 = model(input_ids=torch.tensor(encoded_input).clone().unsqueeze(0).to(device), labels=labels_1)\n",
    "    print(\"loss with labels_1:\", outputs_1.loss)\n",
    "    \n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_1 = torch.argmax(outputs_1.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_1 = hf_tokenizer.decode(predicted_token_ids_1[0], skip_special_tokens=True)\n",
    "    \n",
    "    outputs_2 = model(input_ids=torch.tensor(encoded_input).clone().unsqueeze(0).to(device), labels=labels_2)\n",
    "    print(\"loss with labels_2:\", outputs_2.loss)\n",
    "\n",
    "    # Get the prediction during training\n",
    "    predicted_token_ids_2 = torch.argmax(outputs_2.logits, dim=-1)  # Shape: [batch_size, seq_len]\n",
    "    predicted_string_2 = hf_tokenizer.decode(predicted_token_ids_2[0], skip_special_tokens=True)\n",
    "\n",
    "    # Get the prediction during inference\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).clone().unsqueeze(0).to(device), max_length=len(labels_1[0])).to(device)\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0], skip_special_tokens=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c437825",
   "metadata": {},
   "source": [
    "### TAKEAWAY : LOSS IS NOT ENOUGH!  ORDER/PERMUTATION INVARIANT? Conservation of charges? etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911e3634",
   "metadata": {},
   "source": [
    "Calculate the score :\n",
    "\n",
    "<div align=\"center\">\n",
    "     <h2> S_Lagrangian = S_contraction - P_length </h2>\n",
    "</div>\n",
    "\n",
    "where:\n",
    "- S_contraction = N_correct / N_true\n",
    "- P_length      = N_Extra / N_true     \n",
    "- S_object      = N_correct_objects / N_true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf03ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction        :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 FIELD SPIN 0 ID0 CONTRACTIONS SU3 ID7 ID7 ID6 SU2 ID7 ID6 + FIELD SPIN 0 ID0 FIELD SPIN 0 U1 9 ID9 FIELD SPIN 0 U1 - 9 DAGGER ID2 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID4 FIELD SPIN 0 ID1 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID4 FIELD SPIN 0 ID0 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID4 SU2 ID2 ID4 + FIELD SPIN 0 SU3 - 3 SU2 2 ID4 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID1 CONTRACTIONS SU3 ID4 ID4 ID6 SU2 ID4 ID6 + FIELD SPIN 0 SU3 - 3 SU2 2 ID4 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 CONTRACTIONS SU3 ID4 ID4 ID9 SU3 ID0 ID0 ID2 SU2 ID4 ID9 SU2 ID0 ID2 + FIELD SPIN 0 SU3 - 3 SU2 2 ID4 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID0 CONTRACTIONS SU3 ID4 ID4 ID2 SU3 ID6 ID6 ID0 SU2 ID4 ID6 SU2 ID2 ID0 + FIELD SPIN 0 SU3 - 3 SU2 2 ID4 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID4 ID4 ID0 SU3 ID0 ID1 ID9 SU2 ID4 ID1 SU2 ID0 ID9 + FIELD SPIN 0 SU3 - 3 SU2 2 ID4 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID4 ID4 ID0 SU3 ID0 ID1 ID9 SU2 ID4 ID0 SU2 ID1 ID9 + FIELD SPIN 0 ID8 FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID5 FIELD SPIN 0 U1 - 9 DAGGER ID2 + FIELD SPIN 0 ID7 FIELD SPIN 0 ID6 FIELD SPIN 0 ID0 FIELD SPIN 0 ID2 + FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 9 ID6 FIELD SPIN 0 U1 - 9 DAGGER ID4 FIELD SPIN 0 U1 - 9 DAGGER ID0 + DERIVATIVE SU3 SU2 ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 DERIVATIVE SU3 SU2 ID0 FIELD SPIN 0 SU3 - 3 SU2 2 ID8 CONTRACTIONS LORENTZ ID3 ID0 SU3 ID6 ID8 SU2 ID6 ID8 + DERIVATIVE ID0 FIELD SPIN 0 DAGGER ID6 DERIVATIVE ID8 FIELD SPIN 0 ID9 CONTRACTIONS LORENTZ ID0 ID8 + DERIVATIVE U1 ID2 FIELD SPIN 0 U1 - 9 DAGGER ID4 DERIVATIVE U1 ID0 FIELD SPIN 0 U1 9 ID7 CONTRACTIONS LORENTZ ID2 ID0 - COMMUTATOR_A DERIVATIVE SU3 ID2 COMMUTATOR_B DERIVATIVE SU3 ID4 COMMUTATOR_A DERIVATIVE SU3 ID8 COMMUTATOR_B DERIVATIVE SU3 ID6 CONTRACTIONS LORENTZ ID2 ID8 LORENTZ ID4 ID6 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID6 COMMUTATOR_A DERIVATIVE SU2 ID8 COMMUTATOR_B DERIVATIVE SU2 ID5 CONTRACTIONS LORENTZ ID4 ID8 LORENTZ ID6 ID5 - COMMUTATOR_A DERIVATIVE U1 ID7 COMMUTATOR_B DERIVATIVE U1 ID6 COMMUTATOR_A DERIVATIVE U1 ID0 COMMUTATOR_B DERIVATIVE U1 ID4 CONTRACTIONS LORENTZ ID7 ID0 LORENTZ ID6 ID4 + FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID7 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 CONTRACTIONS SU3 ID7 ID6 SU2 ID7 ID6 + FIELD SPIN 0 DAGGER ID7 FIELD SPIN 0 ID6 CONTRACTIONS + FIELD SPIN 0 U1 - 9 DAGGER ID7 FIELD SPIN 0 U1 9 ID6\n",
      "\n",
      "Truth_1           :  + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3 + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 CONTRACTIONS SU3 ID2 ID2 ID3 SU3 ID0 ID0 ID6 SU2 ID2 ID3 SU2 ID0 ID6 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 CONTRACTIONS SU3 ID5 ID5 ID3 SU3 ID9 ID9 ID2 SU2 ID5 ID9 SU2 ID3 ID2 + FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 CONTRACTIONS SU3 ID0 ID0 ID6 SU3 ID6 ID7 ID8 SU2 ID0 ID7 SU2 ID6 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID5 ID5 ID7 SU3 ID7 ID8 ID9 SU2 ID5 ID7 SU2 ID8 ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID1 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID2 FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 + FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 9 ID1 FIELD SPIN 0 U1 - 9 DAGGER ID6 FIELD SPIN 0 U1 - 9 DAGGER ID0 + DERIVATIVE SU3 SU2 ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 DERIVATIVE SU3 SU2 ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID4 CONTRACTIONS LORENTZ ID1 ID9 SU3 ID3 ID4 SU2 ID3 ID4 + DERIVATIVE ID3 FIELD SPIN 0 DAGGER ID0 DERIVATIVE ID8 FIELD SPIN 0 ID7 CONTRACTIONS LORENTZ ID3 ID8 + DERIVATIVE U1 ID5 FIELD SPIN 0 U1 - 9 DAGGER ID3 DERIVATIVE U1 ID0 FIELD SPIN 0 U1 9 ID6 CONTRACTIONS LORENTZ ID5 ID0 - COMMUTATOR_A DERIVATIVE SU3 ID8 COMMUTATOR_B DERIVATIVE SU3 ID7 COMMUTATOR_A DERIVATIVE SU3 ID3 COMMUTATOR_B DERIVATIVE SU3 ID0 CONTRACTIONS LORENTZ ID8 ID3 LORENTZ ID7 ID0 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID3 CONTRACTIONS LORENTZ ID4 ID7 LORENTZ ID0 ID3 - COMMUTATOR_A DERIVATIVE U1 ID5 COMMUTATOR_B DERIVATIVE U1 ID7 COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID1 CONTRACTIONS LORENTZ ID5 ID4 LORENTZ ID7 ID1 + FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID2 CONTRACTIONS SU3 ID9 ID2 SU2 ID9 ID2 + FIELD SPIN 0 DAGGER ID6 FIELD SPIN 0 ID5 CONTRACTIONS + FIELD SPIN 0 U1 - 9 DAGGER ID7 FIELD SPIN 0 U1 9 ID2 CONTRACTIONS\n",
      "Lagrangian score  :  0.9523809523809523\n",
      "Object score      :  0.9523809523809523\n",
      "Contraction Score :  0.9523809523809523\n",
      "Length penalty    :  0.0\n",
      "\n",
      "Truth_2           :  + FIELD SPIN 0 ID6 FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 - 9 DAGGER ID9 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 ID7 CONTRACTIONS SU3 ID2 ID2 ID3 SU2 ID2 ID3 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID3 FIELD SPIN 0 ID5 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 ID7 FIELD SPIN 0 ID1 CONTRACTIONS SU3 ID2 ID2 ID8 SU2 ID2 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID5 CONTRACTIONS SU3 ID9 ID9 ID3 SU2 ID9 ID3 + FIELD SPIN 0 SU3 - 3 SU2 2 ID2 FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID6 CONTRACTIONS SU3 ID2 ID2 ID3 SU3 ID0 ID0 ID6 SU2 ID2 ID3 SU2 ID0 ID6 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID9 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID2 CONTRACTIONS SU3 ID5 ID5 ID3 SU3 ID9 ID9 ID2 SU2 ID5 ID9 SU2 ID3 ID2 + FIELD SPIN 0 SU3 - 3 SU2 2 ID0 FIELD SPIN 0 SU3 - 3 SU2 2 ID6 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 CONTRACTIONS SU3 ID0 ID0 ID6 SU3 ID6 ID7 ID8 SU2 ID0 ID7 SU2 ID6 ID8 + FIELD SPIN 0 SU3 - 3 SU2 2 ID5 FIELD SPIN 0 SU3 - 3 SU2 2 ID7 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID8 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 CONTRACTIONS SU3 ID5 ID5 ID7 SU3 ID7 ID8 ID9 SU2 ID5 ID7 SU2 ID8 ID9 + FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 FIELD SPIN 0 U1 9 ID8 FIELD SPIN 0 U1 - 9 DAGGER ID1 + FIELD SPIN 0 ID6 FIELD SPIN 0 ID2 FIELD SPIN 0 ID4 FIELD SPIN 0 ID5 + FIELD SPIN 0 U1 9 ID7 FIELD SPIN 0 U1 9 ID1 FIELD SPIN 0 U1 - 9 DAGGER ID6 FIELD SPIN 0 U1 - 9 DAGGER ID0 + DERIVATIVE SU3 SU2 ID1 FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID3 DERIVATIVE SU3 SU2 ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID4 CONTRACTIONS LORENTZ ID1 ID9 SU3 ID3 ID4 SU2 ID3 ID4 + DERIVATIVE ID3 FIELD SPIN 0 DAGGER ID0 DERIVATIVE ID8 FIELD SPIN 0 ID7 CONTRACTIONS LORENTZ ID3 ID8 + DERIVATIVE U1 ID5 FIELD SPIN 0 U1 - 9 DAGGER ID3 DERIVATIVE U1 ID0 FIELD SPIN 0 U1 9 ID6 CONTRACTIONS LORENTZ ID5 ID0 - COMMUTATOR_A DERIVATIVE SU3 ID8 COMMUTATOR_B DERIVATIVE SU3 ID7 COMMUTATOR_A DERIVATIVE SU3 ID3 COMMUTATOR_B DERIVATIVE SU3 ID0 CONTRACTIONS LORENTZ ID8 ID3 LORENTZ ID7 ID0 - COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID3 CONTRACTIONS LORENTZ ID4 ID7 LORENTZ ID0 ID3 - COMMUTATOR_A DERIVATIVE U1 ID5 COMMUTATOR_B DERIVATIVE U1 ID7 COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID1 CONTRACTIONS LORENTZ ID5 ID4 LORENTZ ID7 ID1 + FIELD SPIN 0 SU3 3 SU2 2 DAGGER ID9 FIELD SPIN 0 SU3 - 3 SU2 2 ID2 CONTRACTIONS SU3 ID9 ID2 SU2 ID9 ID2 + FIELD SPIN 0 DAGGER ID6 FIELD SPIN 0 ID5 CONTRACTIONS + FIELD SPIN 0 U1 - 9 DAGGER ID7 FIELD SPIN 0 U1 9 ID2 CONTRACTIONS\n",
      "Lagrangian score  :  0.9523809523809523\n",
      "Object score      :  0.9523809523809523\n",
      "Contraction Score :  0.9523809523809523\n",
      "Length penalty    :  0.0\n"
     ]
    }
   ],
   "source": [
    "lscore_1, obscore_1, conscore_1, lpen_1 = le.get_lagrangian_score(predicted_string,lag_truth_1)\n",
    "lscore_2, obscore_2, conscore_2, lpen_2 = le.get_lagrangian_score(predicted_string,lag_truth_2)\n",
    "\n",
    "print(\"Prediction        : \", predicted_string)\n",
    "print()\n",
    "print(\"Truth_1           : \", lag_truth_1)\n",
    "print(\"Lagrangian score  : \",lscore_1)\n",
    "print(\"Object score      : \",obscore_1)\n",
    "print(\"Contraction Score : \",conscore_1)\n",
    "print(\"Length penalty    : \",lpen_1)\n",
    "print()\n",
    "print(\"Truth_2           : \", lag_truth_2)\n",
    "print(\"Lagrangian score  : \",lscore_2)\n",
    "print(\"Object score      : \",obscore_2)\n",
    "print(\"Contraction Score : \",conscore_2)\n",
    "print(\"Length penalty    : \",lpen_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7b694d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf97e2",
   "metadata": {},
   "source": [
    "# 3B. Embedding analysis : What has it really learned?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72478e40",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is efficiency the only think you need? \n",
    "- Or is it important for you to know whether the model knows what it is learning? \n",
    "\n",
    "Practical Questions : \n",
    "- Can it associate inputs to some embedding space? <br> \n",
    "- Can it understand relations between inputs?  <br> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7a58d",
   "metadata": {},
   "source": [
    "### What is embedding analysis? Basically information encoded in a learned vector space. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9041fe80",
   "metadata": {},
   "source": [
    "<h4> Example in English-German translation : Learned the relationship between input and outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60130ae",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/v2/resize:fit:4800/format:webp/1*52X2L01wpUjy39lIjofC7g.jpeg\" alt=\"Embeddings in LLM\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3bd51",
   "metadata": {},
   "source": [
    "<h4> Example of food words embeddings and their corresponding learned axis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb71eb",
   "metadata": {},
   "source": [
    "<img src=\"https://developers.google.com/static/machine-learning/crash-course/images/embeddings_3D_tangyuan.png\" alt=\"Embeddings in LLM\" width=\"1000\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de8251",
   "metadata": {},
   "source": [
    "### Lagrangian Example : Embeddings of different field symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b25e301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cephyr/users/koay/Alvis/venv/jammymod/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Choose GPU if available\n",
    "import torch\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import lag_eval as le\n",
    "from transformers import BartForConditionalGeneration, PreTrainedTokenizerFast\n",
    "\n",
    "# Load our BART-L model and tokenizer if not yet loaded\n",
    "model_name   = \"JoseEliel/BART-Lagrangian\"\n",
    "model        = BartForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "hf_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2912143c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_dataset_sampled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf huggingface_dataset_sampled.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38daba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data if not already loaded, drop duplicates\n",
    "sampled_df = pd.read_csv(\"huggingface_dataset_sampled.csv\")\n",
    "sampled_df.drop_duplicates(subset=[\"fields\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f8e850",
   "metadata": {},
   "source": [
    "Get all the 1-field scenarios' inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dfb9e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df[\"nfields\"]   = sampled_df[\"fields\"].apply(lambda x: x.count(\"FIELD\"))\n",
    "sampled_1f_scenarios_df = sampled_df[sampled_df[\"nfields\"]==1]\n",
    "sampled_1f_scenarios_df = sampled_1f_scenarios_df.sample(1000)\n",
    "fields                  = sampled_1f_scenarios_df[\"fields\"].apply(lambda x: set([\"FIELD \"+k for k in x.split(\"FIELD \") if k != \"\"])).to_list()\n",
    "uniq_fields_list_1f     = list(set.union(*(fields)))\n",
    "uniq_fields_list_1f     = [str((\"[SOS] \"+ k + \" [EOS]\").replace(\"  \",\" \")) for k in uniq_fields_list_1f]\n",
    "uniq_fields_list_1f     = np.unique(uniq_fields_list_1f).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9db4d73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 1 / 2 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 2 / 3 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 2 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 3 / 5 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 3 / 7 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 4 / 3 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 4 / 5 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 4 / 7 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 5 / 4 [EOS]\n",
      "[SOS] FIELD SPIN 0 SU2 2 U1 - 5 / 8 [EOS]\n"
     ]
    }
   ],
   "source": [
    "# Have a look at the first 10 unique fields\n",
    "for i in uniq_fields_list_1f[:10]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822bba06",
   "metadata": {},
   "source": [
    "Generate embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc2611",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/Has37yz.png\" alt=\"Embeddings in LLM\" width=\"600\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cef2e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/local/tmp.4012525/ipykernel_232528/595248388.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_loader  = DataLoader( torch.tensor(inputs_batch[\"input_ids\"]).to(device), batch_size=32)\n",
      "100%|| 32/32 [00:04<00:00,  6.41it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "inputs_batch = hf_tokenizer(uniq_fields_list_1f, return_tensors='pt', truncation=True,padding=True).to(device)\n",
    "data_loader  = DataLoader( torch.tensor(inputs_batch[\"input_ids\"]).to(device), batch_size=32)\n",
    "\n",
    "\n",
    "# Example of getting embeddings of specific cases\n",
    "all_embedding_1f = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for xinput in tqdm(data_loader):\n",
    "        outputs = model(xinput.to(device), output_hidden_states=True)\n",
    "        # Get the embeddings, which we choose to be the encoder's last hidden state of the first token\n",
    "        embeddings_enc = outputs.encoder_last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embedding_1f.append( torch.tensor(embeddings_enc))\n",
    "\n",
    "all_embedding_1f = torch.cat(all_embedding_1f, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8bc6f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1024])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embedding_1f.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154db3b",
   "metadata": {},
   "source": [
    "Reduced the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "671d4a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3)\n",
    "tsne_results = tsne.fit_transform(all_embedding_1f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "56820673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6deaf1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_3d_tsne(tsne_results, clusters_dat, with_noise=True,elev=30, azim=30,info_dict=None,cluster_order=None,title=\"3D Clusters of BART\"):\n",
    "    \"\"\"\n",
    "    Plots a 3D scatter plot of t-SNE results\n",
    "    \n",
    "    Parameters:\n",
    "    - tsne_results (numpy.ndarray): The 3D coordinates from t-SNE, shape (n_samples, 3).\n",
    "    - clusters_dat (numpy.ndarray): The cluster labels from DBSCAN, shape (n_samples,).\n",
    "    - elev (float): Elevation angle for the 3D plot.\n",
    "    - azim (float): Azimuthal angle for the 3D plot.\n",
    "    \"\"\"\n",
    "    if cluster_order is None: cluster_order = np.unique(clusters_dat)\n",
    "\n",
    "    colors = plt.colormaps['tab20']\n",
    "    \n",
    "    if info_dict is not None: cluster_colors = {cluster: colors(i) for i, cluster in enumerate(info_dict.keys())}\n",
    "    else                    : cluster_colors = {cluster: colors(i) for i, cluster in enumerate(cluster_order)}\n",
    "\n",
    "    # Create an interactive 3D scatter plot\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    for cluster in cluster_order:\n",
    "        if not with_noise and cluster == -1: continue\n",
    "        cluster_points = tsne_results[np.array(clusters_dat) == cluster]\n",
    "        if info_dict is None:\n",
    "            cluster_label=f'Cluster {cluster}'\n",
    "        else:\n",
    "            try    :cluster_label=f'{info_dict[cluster][\"tag\"]}'\n",
    "            except :cluster_label=f'{info_dict[cluster]}'\n",
    "\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], cluster_points[:, 2], \n",
    "                       color=cluster_colors[cluster], label=cluster_label, alpha=0.7)\n",
    "\n",
    "    \n",
    "    ax.legend(loc='lower right', fontsize=\"medium\", bbox_to_anchor=(.35, .65))\n",
    "\n",
    "    # Setting labels and title\n",
    "    ax.set_xlabel('TSNE Component 1',fontsize=\"medium\")\n",
    "    ax.set_ylabel('TSNE Component 2',fontsize=\"medium\")\n",
    "    ax.set_zlabel('TSNE Component 3',fontsize=\"medium\")\n",
    "    ax.tick_params(labelsize=\"small\")    # Use ax.set_title() for a 3D plot and adjust the padding\n",
    "    # Use fig.suptitle instead of ax.set_title for better control\n",
    "    fig.suptitle(title, fontsize=\"large\")  # y controls the vertical position; lower values move it closer to the plot\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)  # You can further lower the top value to move the plot down\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28c65e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6e7914129c46f2ba7c65df257b4bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(sampled_1f_scenarios_df[\"nfields\"].to_numpy()), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed({1:\"Embedded Vectors\"}),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\" clusters\")\n",
    "                    )\n",
    "\n",
    "# in case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=sampled_1f_scenarios_df[\"nfields\"].to_numpy(),with_noise=True, elev=30, azim=30,info_dict={1:\"Embedded Vectors\"},cluster_order=None,title=\"3D Clusters of BART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "24ced615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "533429131058421688d594dcc24db832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_SPIN_dat_true   = [\"A\" if \"SPIN 0\" in j else \"B\" if (\"SPIN 0\" not in j and \"HEL 1\" not in j) else \"C\" if (\"SPIN 0\" not in j and \"HEL 1\" in j) else \"D\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SPIN_info_dict  = {\"B\":r\"$\\psi_L$\" + \" : LH Fermions\",\"C\":r\"$\\psi_R$\" + \" : RH Fermions\",\"A\":r\"$\\phi$\" + \" : Scalars\" ,\"D\":\"?\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SPIN_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SPIN_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SPIN clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SPIN_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SPIN_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "875d2326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fea6435c353449f85b4807b71697e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_SU3_dat_true  = [\"3\" if \"SU3 3\" in j else r\"$\\overline{3}$\" if \"SU3 - 3\" in j    else \"1\" for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU3_info_dict = {\"3\":\"3: Triplets\"     ,r\"$\\overline{3}$\":r\"$\\overline{3}$\" + \": Anti-Triplets\"     ,\"1\":\"1: Singlets\" }\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU3_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU3_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SU3 clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU3_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU3_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7648d7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56137cb5b15f44238a869e2e8719197a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=30.0, description='Elev', max=90.0, step=1.0), FloatSlider(value=84.0,"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_SU2_dat_true  = [3 if \"SU2 3\" in j else 2 if \"SU2 2\" in j    else 1 for i,j in zip(tsne_results,uniq_fields_list_1f)  ]\n",
    "cluster_SU2_info_dict = {3:\"3 : Triplets\"     ,2:\"2 : Doublets\"     ,1:\"1 : Singlets\" }\n",
    "\n",
    "\n",
    "elev_slider = widgets.FloatSlider(min=0, max=90, step=1, value=30, description='Elev')\n",
    "azim_slider = widgets.FloatSlider(min=0, max=360, step=1, value=84, description='Azim')\n",
    "widgets.interactive(plot_3d_tsne, \n",
    "                    tsne_results   = widgets.fixed(tsne_results), \n",
    "                    clusters_dat   = widgets.fixed(cluster_SU2_dat_true), \n",
    "                    with_noise     = widgets.fixed(True),\n",
    "                    elev           = elev_slider, \n",
    "                    azim           = azim_slider,\n",
    "                    info_dict      = widgets.fixed(cluster_SU2_info_dict),\n",
    "                    cluster_order  = widgets.fixed(None),\n",
    "                    title          = widgets.fixed(\"SU2 clusters\")\n",
    "                    )\n",
    "\n",
    "# In case widgets are not available\n",
    "# plot_3d_tsne(tsne_results, clusters_dat=cluster_SU2_dat_true,with_noise=False, elev=30, azim=30,info_dict=cluster_SU2_info_dict,cluster_order=None,title=\"Lorentz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398b9ae3",
   "metadata": {},
   "source": [
    "### TAKEAWAY : Embedding shows whether it had \"understood\" concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77787d14",
   "metadata": {},
   "source": [
    "# 3C. Out-Of-Distribution Generalization : Can it go beyond what its trained? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c5fcd2",
   "metadata": {},
   "source": [
    "Considerations : \n",
    "- Is your problem's \"data space\" very big? \n",
    "- Is the probability of an unseen case high? \n",
    "- If yes, then chances of OOD data cases are high. \n",
    "- Do you want to think about the next archietcture?\n",
    "\n",
    "Practical Questions : \n",
    "- Can it work with never seen scenarios? What is your OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e0297f",
   "metadata": {},
   "source": [
    "### What are OOD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b4cf6",
   "metadata": {},
   "source": [
    "OOD for images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e556f8",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/lS2Ghrw.png\" alt=\"Distribtuion\" width=\"600\"><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83434890",
   "metadata": {},
   "source": [
    "OOD for addition\n",
    "- Trained on numbers up to 100 \n",
    "- Test it on numbers beyond 100 eg. 102031232783109 + 328109389103 \n",
    "\n",
    "OOD for Lagrangians\n",
    "- Trained on Lagrangians with 6 Fields\n",
    "- Test it on Lagrangians beyond 6 Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bcb0e",
   "metadata": {},
   "source": [
    "## Example : Your Training Data decides your OOD scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb5a097",
   "metadata": {},
   "source": [
    "Lagrangian Example : \n",
    "- Trained on single-digit integers or single-digit fractions :  1 / 2 \n",
    "- Test on two-digit integers : 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4facd3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 0 SU2 2 U1 1 / 2 [EOS]\n",
      "token_id =  [0, 22, 36, 9, 37, 6, 39, 5, 4, 6, 1]\n",
      "decoded  =  [SOS] FIELD SPIN 0 SU2 2 U1 1 / 2 [EOS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "InD_example           = \"FIELD SPIN 0 SU2 2 U1 1 / 2\"\n",
    "    \n",
    "example_input   = \"[SOS] \"+InD_example+\" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f641cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : \n",
      "+ FIELD SPIN 0 SU2 2 U1 1 / 2 ID6 FIELD SPIN 0 SU2 2 U1 1 / 2 ID0 FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID4 FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID1 CONTRACTIONS SU2 ID6 ID4 SU2 ID0 ID1\n",
      "+ FIELD SPIN 0 SU2 2 U1 1 / 2 ID4 FIELD SPIN 0 SU2 2 U1 1 / 2 ID6 FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID1 FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID0 CONTRACTIONS SU2 ID4 ID6 SU2 ID1 ID0\n",
      "+ DERIVATIVE SU2 U1 ID4 FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID8 DERIVATIVE SU2 U1 ID6 FIELD SPIN 0 SU2 2 U1 1 / 2 ID5 CONTRACTIONS LORENTZ ID4 ID6 SU2 ID8 ID5\n",
      "- COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID8 COMMUTATOR_A DERIVATIVE SU2 ID6 COMMUTATOR_B DERIVATIVE SU2 ID5 CONTRACTIONS LORENTZ ID4 ID6 LORENTZ ID8 ID5\n",
      "- COMMUTATOR_A DERIVATIVE U1 ID4 COMMUTATOR_B DERIVATIVE U1 ID8 COMMUTATOR_A DERIVATIVE U1 ID6 COMMUTATOR_B DERIVATIVE U1 ID5 CONTRACTIONS LORENTZ ID4 ID6 LORENTZ ID8 ID5\n",
      "+ FIELD SPIN 0 SU2 2 U1 - 1 / 2 DAGGER ID4 FIELD SPIN 0 SU2 2 U1 1 / 2 ID8 CONTRACTIONS SU2 ID4 ID8\n"
     ]
    }
   ],
   "source": [
    "## Generate the Lagrangian!\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # loss with labels_1 and labels_2\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0).to(device), max_length=1024)\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0].to(device), skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted : \", )\n",
    "for i in le.sep_terms(predicted_string):\n",
    "    print(\" \".join(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdf832",
   "metadata": {},
   "source": [
    "Lets try fields with u(1) charge = 40!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ab258d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input    =  [SOS] FIELD SPIN 0 SU2 2 U1 4 0 [EOS]\n",
      "token_id =  [0, 22, 36, 9, 37, 6, 39, 11, 9, 1]\n",
      "decoded  =  [SOS] FIELD SPIN 0 SU2 2 U1 4 0 [EOS]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ood_example           = \"FIELD SPIN 0 SU2 2 U1 4 0\"\n",
    "    \n",
    "example_input   = \"[SOS] \"+ood_example+\" [EOS]\"\n",
    "print(\"Input    = \",example_input)\n",
    "\n",
    "encoded_input = hf_tokenizer.encode(example_input)\n",
    "print(\"token_id = \", encoded_input)\n",
    "\n",
    "decoded_input = hf_tokenizer.decode(encoded_input)\n",
    "print(\"decoded  = \", decoded_input)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bd034fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted : \n",
      "+ FIELD SPIN 0 SU2 2 U1 4 ID0 FIELD SPIN 0 SU2 2 U1 4 ID6 FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID4 FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID1 CONTRACTIONS SU2 ID0 ID4 SU2 ID6 ID1\n",
      "+ FIELD SPIN 0 SU2 2 U1 4 ID7 FIELD SPIN 0 SU2 2 U1 4 ID0 FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID9 FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID6 CONTRACTIONS SU2 ID7 ID0 SU2 ID9 ID6\n",
      "+ DERIVATIVE SU2 U1 ID1 FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID4 DERIVATIVE SU2 U1 ID0 FIELD SPIN 0 SU2 2 U1 4 ID9 CONTRACTIONS LORENTZ ID1 ID0 SU2 ID4 ID9\n",
      "- COMMUTATOR_A DERIVATIVE SU2 ID7 COMMUTATOR_B DERIVATIVE SU2 ID0 COMMUTATOR_A DERIVATIVE SU2 ID4 COMMUTATOR_B DERIVATIVE SU2 ID1 CONTRACTIONS LORENTZ ID7 ID4 LORENTZ ID0 ID1\n",
      "- COMMUTATOR_A DERIVATIVE U1 ID7 COMMUTATOR_B DERIVATIVE U1 ID0 COMMUTATOR_A DERIVATIVE U1 ID2 COMMUTATOR_B DERIVATIVE U1 ID6 CONTRACTIONS LORENTZ ID7 ID2 LORENTZ ID0 ID6\n",
      "+ FIELD SPIN 0 SU2 2 U1 - 4 DAGGER ID7 FIELD SPIN 0 SU2 2 U1 4 ID6 CONTRACTIONS SU2 ID7 ID6\n"
     ]
    }
   ],
   "source": [
    "## Generate the Lagrangian!\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # loss with labels_1 and labels_2\n",
    "    generated_id     = model.generate(input_ids=torch.tensor(encoded_input).unsqueeze(0).to(device), max_length=1024)\n",
    "    predicted_string = hf_tokenizer.decode(generated_id[0].to(device), skip_special_tokens=True)\n",
    "\n",
    "print(\"Predicted : \", )\n",
    "for i in le.sep_terms(predicted_string):\n",
    "    print(\" \".join(i))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34fb221",
   "metadata": {},
   "source": [
    "We see that it cant understand 40 as a number, it assuming the field has charge=4 instead of 40. <br>\n",
    "As it has never even seen two-digit charges, it interpolates! OOD not as good!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55da998",
   "metadata": {},
   "source": [
    "# Acknowledge SUPR\n",
    "The computations and data handling were enabled by resources provided by the National Academic Infrastructure for Supercomputing in Sweden (NAISS) from projects NAISS 2025/22-521, partially funded by the Swedish Research Council through grant agreement no. 2022-06725"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
