{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e9cfec",
   "metadata": {},
   "source": [
    "# Based on conversation with ChatGPT : https://chatgpt.com/share/67f4f246-0b88-8012-87c1-8f9023ea0571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd47d82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-08 11:48:11.403152: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-08 11:48:11.445784: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-08 11:48:12.231793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa966cac514841aeb7b3c227e5024554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ys/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkysheng\u001b[0m (\u001b[33mml-thep\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ys/YS/uppsala/conferences/ai4physics workshop/AI4Physics-learning-workshop/wandb/run-20250408_114816-tpkskqnw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ml-thep/huggingface/runs/tpkskqnw' target=\"_blank\">youthful-eon-30</a></strong> to <a href='https://wandb.ai/ml-thep/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ml-thep/huggingface' target=\"_blank\">https://wandb.ai/ml-thep/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ml-thep/huggingface/runs/tpkskqnw' target=\"_blank\">https://wandb.ai/ml-thep/huggingface/runs/tpkskqnw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ba5f48c1c344e19b3077d9d908a1e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0079, 'learning_rate': 4.973333333333334e-05, 'epoch': 0.16}\n",
      "{'loss': 4.5496, 'learning_rate': 4.9466666666666665e-05, 'epoch': 0.32}\n",
      "{'loss': 4.1008, 'learning_rate': 4.92e-05, 'epoch': 0.48}\n",
      "{'loss': 3.6964, 'learning_rate': 4.8933333333333335e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.3176, 'learning_rate': 4.866666666666667e-05, 'epoch': 0.8}\n",
      "{'loss': 2.9865, 'learning_rate': 4.8400000000000004e-05, 'epoch': 0.96}\n",
      "{'loss': 2.6933, 'learning_rate': 4.8133333333333336e-05, 'epoch': 1.12}\n",
      "{'loss': 2.4382, 'learning_rate': 4.7866666666666674e-05, 'epoch': 1.28}\n",
      "{'loss': 2.1985, 'learning_rate': 4.76e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9897, 'learning_rate': 4.7333333333333336e-05, 'epoch': 1.6}\n",
      "{'loss': 1.8252, 'learning_rate': 4.706666666666667e-05, 'epoch': 1.76}\n",
      "{'loss': 1.6935, 'learning_rate': 4.6800000000000006e-05, 'epoch': 1.92}\n",
      "{'loss': 1.5914, 'learning_rate': 4.653333333333334e-05, 'epoch': 2.08}\n",
      "{'loss': 1.5142, 'learning_rate': 4.626666666666667e-05, 'epoch': 2.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4621, 'learning_rate': 4.600000000000001e-05, 'epoch': 2.4}\n",
      "{'loss': 1.4235, 'learning_rate': 4.573333333333333e-05, 'epoch': 2.56}\n",
      "{'loss': 1.397, 'learning_rate': 4.546666666666667e-05, 'epoch': 2.72}\n",
      "{'loss': 1.3782, 'learning_rate': 4.52e-05, 'epoch': 2.88}\n",
      "{'loss': 1.3643, 'learning_rate': 4.493333333333333e-05, 'epoch': 3.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3496, 'learning_rate': 4.466666666666667e-05, 'epoch': 3.2}\n",
      "{'loss': 1.3384, 'learning_rate': 4.44e-05, 'epoch': 3.36}\n",
      "{'loss': 1.34, 'learning_rate': 4.413333333333334e-05, 'epoch': 3.52}\n",
      "{'loss': 1.3284, 'learning_rate': 4.3866666666666665e-05, 'epoch': 3.68}\n",
      "{'loss': 1.3255, 'learning_rate': 4.36e-05, 'epoch': 3.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3188, 'learning_rate': 4.3333333333333334e-05, 'epoch': 4.0}\n",
      "{'loss': 1.3131, 'learning_rate': 4.3066666666666665e-05, 'epoch': 4.16}\n",
      "{'loss': 1.3107, 'learning_rate': 4.2800000000000004e-05, 'epoch': 4.32}\n",
      "{'loss': 1.3082, 'learning_rate': 4.2533333333333335e-05, 'epoch': 4.48}\n",
      "{'loss': 1.3023, 'learning_rate': 4.226666666666667e-05, 'epoch': 4.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3059, 'learning_rate': 4.2e-05, 'epoch': 4.8}\n",
      "{'loss': 1.3028, 'learning_rate': 4.1733333333333336e-05, 'epoch': 4.96}\n",
      "{'loss': 1.3026, 'learning_rate': 4.146666666666667e-05, 'epoch': 5.12}\n",
      "{'loss': 1.2972, 'learning_rate': 4.12e-05, 'epoch': 5.28}\n",
      "{'loss': 1.2941, 'learning_rate': 4.093333333333334e-05, 'epoch': 5.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2971, 'learning_rate': 4.066666666666667e-05, 'epoch': 5.6}\n",
      "{'loss': 1.2908, 'learning_rate': 4.0400000000000006e-05, 'epoch': 5.76}\n",
      "{'loss': 1.2935, 'learning_rate': 4.013333333333333e-05, 'epoch': 5.92}\n",
      "{'loss': 1.2918, 'learning_rate': 3.986666666666667e-05, 'epoch': 6.08}\n",
      "{'loss': 1.2908, 'learning_rate': 3.960000000000001e-05, 'epoch': 6.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2903, 'learning_rate': 3.933333333333333e-05, 'epoch': 6.4}\n",
      "{'loss': 1.2947, 'learning_rate': 3.906666666666667e-05, 'epoch': 6.56}\n",
      "{'loss': 1.2851, 'learning_rate': 3.88e-05, 'epoch': 6.72}\n",
      "{'loss': 1.2858, 'learning_rate': 3.853333333333334e-05, 'epoch': 6.88}\n",
      "{'loss': 1.284, 'learning_rate': 3.8266666666666664e-05, 'epoch': 7.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2852, 'learning_rate': 3.8e-05, 'epoch': 7.2}\n",
      "{'loss': 1.2848, 'learning_rate': 3.773333333333334e-05, 'epoch': 7.36}\n",
      "{'loss': 1.2859, 'learning_rate': 3.7466666666666665e-05, 'epoch': 7.52}\n",
      "{'loss': 1.2796, 'learning_rate': 3.72e-05, 'epoch': 7.68}\n",
      "{'loss': 1.2802, 'learning_rate': 3.6933333333333334e-05, 'epoch': 7.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2814, 'learning_rate': 3.6666666666666666e-05, 'epoch': 8.0}\n",
      "{'loss': 1.2724, 'learning_rate': 3.6400000000000004e-05, 'epoch': 8.16}\n",
      "{'loss': 1.2754, 'learning_rate': 3.6133333333333335e-05, 'epoch': 8.32}\n",
      "{'loss': 1.2689, 'learning_rate': 3.586666666666667e-05, 'epoch': 8.48}\n",
      "{'loss': 1.267, 'learning_rate': 3.56e-05, 'epoch': 8.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2622, 'learning_rate': 3.5333333333333336e-05, 'epoch': 8.8}\n",
      "{'loss': 1.2598, 'learning_rate': 3.506666666666667e-05, 'epoch': 8.96}\n",
      "{'loss': 1.2626, 'learning_rate': 3.48e-05, 'epoch': 9.12}\n",
      "{'loss': 1.2548, 'learning_rate': 3.453333333333334e-05, 'epoch': 9.28}\n",
      "{'loss': 1.2504, 'learning_rate': 3.426666666666667e-05, 'epoch': 9.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2461, 'learning_rate': 3.4000000000000007e-05, 'epoch': 9.6}\n",
      "{'loss': 1.2458, 'learning_rate': 3.373333333333333e-05, 'epoch': 9.76}\n",
      "{'loss': 1.2428, 'learning_rate': 3.346666666666667e-05, 'epoch': 9.92}\n",
      "{'loss': 1.2439, 'learning_rate': 3.32e-05, 'epoch': 10.08}\n",
      "{'loss': 1.2398, 'learning_rate': 3.293333333333333e-05, 'epoch': 10.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2392, 'learning_rate': 3.266666666666667e-05, 'epoch': 10.4}\n",
      "{'loss': 1.2368, 'learning_rate': 3.24e-05, 'epoch': 10.56}\n",
      "{'loss': 1.2343, 'learning_rate': 3.213333333333334e-05, 'epoch': 10.72}\n",
      "{'loss': 1.2349, 'learning_rate': 3.1866666666666664e-05, 'epoch': 10.88}\n",
      "{'loss': 1.2333, 'learning_rate': 3.16e-05, 'epoch': 11.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2331, 'learning_rate': 3.1333333333333334e-05, 'epoch': 11.2}\n",
      "{'loss': 1.2305, 'learning_rate': 3.1066666666666665e-05, 'epoch': 11.36}\n",
      "{'loss': 1.2265, 'learning_rate': 3.08e-05, 'epoch': 11.52}\n",
      "{'loss': 1.2292, 'learning_rate': 3.0533333333333335e-05, 'epoch': 11.68}\n",
      "{'loss': 1.2256, 'learning_rate': 3.0266666666666666e-05, 'epoch': 11.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2269, 'learning_rate': 3e-05, 'epoch': 12.0}\n",
      "{'loss': 1.2233, 'learning_rate': 2.9733333333333336e-05, 'epoch': 12.16}\n",
      "{'loss': 1.2292, 'learning_rate': 2.946666666666667e-05, 'epoch': 12.32}\n",
      "{'loss': 1.2215, 'learning_rate': 2.9199999999999998e-05, 'epoch': 12.48}\n",
      "{'loss': 1.217, 'learning_rate': 2.8933333333333333e-05, 'epoch': 12.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2213, 'learning_rate': 2.8666666666666668e-05, 'epoch': 12.8}\n",
      "{'loss': 1.2209, 'learning_rate': 2.84e-05, 'epoch': 12.96}\n",
      "{'loss': 1.2185, 'learning_rate': 2.8133333333333334e-05, 'epoch': 13.12}\n",
      "{'loss': 1.2133, 'learning_rate': 2.786666666666667e-05, 'epoch': 13.28}\n",
      "{'loss': 1.2215, 'learning_rate': 2.7600000000000003e-05, 'epoch': 13.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2147, 'learning_rate': 2.733333333333333e-05, 'epoch': 13.6}\n",
      "{'loss': 1.2138, 'learning_rate': 2.706666666666667e-05, 'epoch': 13.76}\n",
      "{'loss': 1.2177, 'learning_rate': 2.6800000000000004e-05, 'epoch': 13.92}\n",
      "{'loss': 1.2126, 'learning_rate': 2.6533333333333332e-05, 'epoch': 14.08}\n",
      "{'loss': 1.2066, 'learning_rate': 2.6266666666666667e-05, 'epoch': 14.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2125, 'learning_rate': 2.6000000000000002e-05, 'epoch': 14.4}\n",
      "{'loss': 1.2091, 'learning_rate': 2.5733333333333337e-05, 'epoch': 14.56}\n",
      "{'loss': 1.2112, 'learning_rate': 2.5466666666666668e-05, 'epoch': 14.72}\n",
      "{'loss': 1.211, 'learning_rate': 2.5200000000000003e-05, 'epoch': 14.88}\n",
      "{'loss': 1.2063, 'learning_rate': 2.4933333333333334e-05, 'epoch': 15.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2067, 'learning_rate': 2.466666666666667e-05, 'epoch': 15.2}\n",
      "{'loss': 1.2025, 'learning_rate': 2.44e-05, 'epoch': 15.36}\n",
      "{'loss': 1.2098, 'learning_rate': 2.4133333333333335e-05, 'epoch': 15.52}\n",
      "{'loss': 1.1989, 'learning_rate': 2.3866666666666666e-05, 'epoch': 15.68}\n",
      "{'loss': 1.2035, 'learning_rate': 2.36e-05, 'epoch': 15.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2084, 'learning_rate': 2.3333333333333336e-05, 'epoch': 16.0}\n",
      "{'loss': 1.2028, 'learning_rate': 2.3066666666666667e-05, 'epoch': 16.16}\n",
      "{'loss': 1.2025, 'learning_rate': 2.2800000000000002e-05, 'epoch': 16.32}\n",
      "{'loss': 1.2007, 'learning_rate': 2.2533333333333333e-05, 'epoch': 16.48}\n",
      "{'loss': 1.1987, 'learning_rate': 2.2266666666666668e-05, 'epoch': 16.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2022, 'learning_rate': 2.2000000000000003e-05, 'epoch': 16.8}\n",
      "{'loss': 1.1971, 'learning_rate': 2.1733333333333334e-05, 'epoch': 16.96}\n",
      "{'loss': 1.1983, 'learning_rate': 2.146666666666667e-05, 'epoch': 17.12}\n",
      "{'loss': 1.1951, 'learning_rate': 2.12e-05, 'epoch': 17.28}\n",
      "{'loss': 1.1974, 'learning_rate': 2.0933333333333335e-05, 'epoch': 17.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1966, 'learning_rate': 2.0666666666666666e-05, 'epoch': 17.6}\n",
      "{'loss': 1.1951, 'learning_rate': 2.04e-05, 'epoch': 17.76}\n",
      "{'loss': 1.1977, 'learning_rate': 2.0133333333333336e-05, 'epoch': 17.92}\n",
      "{'loss': 1.1911, 'learning_rate': 1.9866666666666667e-05, 'epoch': 18.08}\n",
      "{'loss': 1.1899, 'learning_rate': 1.9600000000000002e-05, 'epoch': 18.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1906, 'learning_rate': 1.9333333333333333e-05, 'epoch': 18.4}\n",
      "{'loss': 1.1915, 'learning_rate': 1.9066666666666668e-05, 'epoch': 18.56}\n",
      "{'loss': 1.1875, 'learning_rate': 1.88e-05, 'epoch': 18.72}\n",
      "{'loss': 1.1957, 'learning_rate': 1.8533333333333334e-05, 'epoch': 18.88}\n",
      "{'loss': 1.1908, 'learning_rate': 1.826666666666667e-05, 'epoch': 19.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.189, 'learning_rate': 1.8e-05, 'epoch': 19.2}\n",
      "{'loss': 1.1886, 'learning_rate': 1.7733333333333335e-05, 'epoch': 19.36}\n",
      "{'loss': 1.185, 'learning_rate': 1.7466666666666667e-05, 'epoch': 19.52}\n",
      "{'loss': 1.1854, 'learning_rate': 1.7199999999999998e-05, 'epoch': 19.68}\n",
      "{'loss': 1.1842, 'learning_rate': 1.6933333333333333e-05, 'epoch': 19.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1826, 'learning_rate': 1.6666666666666667e-05, 'epoch': 20.0}\n",
      "{'loss': 1.1821, 'learning_rate': 1.6400000000000002e-05, 'epoch': 20.16}\n",
      "{'loss': 1.1809, 'learning_rate': 1.6133333333333334e-05, 'epoch': 20.32}\n",
      "{'loss': 1.1788, 'learning_rate': 1.586666666666667e-05, 'epoch': 20.48}\n",
      "{'loss': 1.1827, 'learning_rate': 1.56e-05, 'epoch': 20.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.174, 'learning_rate': 1.5333333333333334e-05, 'epoch': 20.8}\n",
      "{'loss': 1.1773, 'learning_rate': 1.5066666666666668e-05, 'epoch': 20.96}\n",
      "{'loss': 1.1785, 'learning_rate': 1.48e-05, 'epoch': 21.12}\n",
      "{'loss': 1.1737, 'learning_rate': 1.4533333333333335e-05, 'epoch': 21.28}\n",
      "{'loss': 1.1716, 'learning_rate': 1.4266666666666667e-05, 'epoch': 21.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1684, 'learning_rate': 1.4000000000000001e-05, 'epoch': 21.6}\n",
      "{'loss': 1.1669, 'learning_rate': 1.3733333333333335e-05, 'epoch': 21.76}\n",
      "{'loss': 1.1645, 'learning_rate': 1.3466666666666666e-05, 'epoch': 21.92}\n",
      "{'loss': 1.1686, 'learning_rate': 1.32e-05, 'epoch': 22.08}\n",
      "{'loss': 1.1604, 'learning_rate': 1.2933333333333334e-05, 'epoch': 22.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.16, 'learning_rate': 1.2666666666666668e-05, 'epoch': 22.4}\n",
      "{'loss': 1.1639, 'learning_rate': 1.24e-05, 'epoch': 22.56}\n",
      "{'loss': 1.161, 'learning_rate': 1.2133333333333335e-05, 'epoch': 22.72}\n",
      "{'loss': 1.1592, 'learning_rate': 1.1866666666666668e-05, 'epoch': 22.88}\n",
      "{'loss': 1.1585, 'learning_rate': 1.16e-05, 'epoch': 23.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1585, 'learning_rate': 1.1333333333333334e-05, 'epoch': 23.2}\n",
      "{'loss': 1.1556, 'learning_rate': 1.1066666666666667e-05, 'epoch': 23.36}\n",
      "{'loss': 1.1579, 'learning_rate': 1.08e-05, 'epoch': 23.52}\n",
      "{'loss': 1.1526, 'learning_rate': 1.0533333333333335e-05, 'epoch': 23.68}\n",
      "{'loss': 1.153, 'learning_rate': 1.0266666666666668e-05, 'epoch': 23.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1512, 'learning_rate': 1e-05, 'epoch': 24.0}\n",
      "{'loss': 1.1503, 'learning_rate': 9.733333333333334e-06, 'epoch': 24.16}\n",
      "{'loss': 1.1516, 'learning_rate': 9.466666666666667e-06, 'epoch': 24.32}\n",
      "{'loss': 1.1508, 'learning_rate': 9.2e-06, 'epoch': 24.48}\n",
      "{'loss': 1.1505, 'learning_rate': 8.933333333333333e-06, 'epoch': 24.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1494, 'learning_rate': 8.666666666666668e-06, 'epoch': 24.8}\n",
      "{'loss': 1.1489, 'learning_rate': 8.400000000000001e-06, 'epoch': 24.96}\n",
      "{'loss': 1.1457, 'learning_rate': 8.133333333333332e-06, 'epoch': 25.12}\n",
      "{'loss': 1.1461, 'learning_rate': 7.866666666666667e-06, 'epoch': 25.28}\n",
      "{'loss': 1.1446, 'learning_rate': 7.6e-06, 'epoch': 25.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1473, 'learning_rate': 7.333333333333334e-06, 'epoch': 25.6}\n",
      "{'loss': 1.1451, 'learning_rate': 7.066666666666667e-06, 'epoch': 25.76}\n",
      "{'loss': 1.1455, 'learning_rate': 6.800000000000001e-06, 'epoch': 25.92}\n",
      "{'loss': 1.1479, 'learning_rate': 6.533333333333333e-06, 'epoch': 26.08}\n",
      "{'loss': 1.1425, 'learning_rate': 6.266666666666666e-06, 'epoch': 26.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1443, 'learning_rate': 6e-06, 'epoch': 26.4}\n",
      "{'loss': 1.145, 'learning_rate': 5.733333333333333e-06, 'epoch': 26.56}\n",
      "{'loss': 1.1417, 'learning_rate': 5.466666666666667e-06, 'epoch': 26.72}\n",
      "{'loss': 1.1444, 'learning_rate': 5.2e-06, 'epoch': 26.88}\n",
      "{'loss': 1.1425, 'learning_rate': 4.933333333333333e-06, 'epoch': 27.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1409, 'learning_rate': 4.666666666666667e-06, 'epoch': 27.2}\n",
      "{'loss': 1.1452, 'learning_rate': 4.4e-06, 'epoch': 27.36}\n",
      "{'loss': 1.1441, 'learning_rate': 4.133333333333333e-06, 'epoch': 27.52}\n",
      "{'loss': 1.1412, 'learning_rate': 3.866666666666667e-06, 'epoch': 27.68}\n",
      "{'loss': 1.1417, 'learning_rate': 3.6e-06, 'epoch': 27.84}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1403, 'learning_rate': 3.3333333333333333e-06, 'epoch': 28.0}\n",
      "{'loss': 1.1456, 'learning_rate': 3.066666666666667e-06, 'epoch': 28.16}\n",
      "{'loss': 1.1367, 'learning_rate': 2.8000000000000003e-06, 'epoch': 28.32}\n",
      "{'loss': 1.1402, 'learning_rate': 2.5333333333333334e-06, 'epoch': 28.48}\n",
      "{'loss': 1.1357, 'learning_rate': 2.266666666666667e-06, 'epoch': 28.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.139, 'learning_rate': 2.0000000000000003e-06, 'epoch': 28.8}\n",
      "{'loss': 1.1399, 'learning_rate': 1.7333333333333334e-06, 'epoch': 28.96}\n",
      "{'loss': 1.1442, 'learning_rate': 1.4666666666666667e-06, 'epoch': 29.12}\n",
      "{'loss': 1.1393, 'learning_rate': 1.2000000000000002e-06, 'epoch': 29.28}\n",
      "{'loss': 1.1374, 'learning_rate': 9.333333333333334e-07, 'epoch': 29.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1426, 'learning_rate': 6.666666666666667e-07, 'epoch': 29.6}\n",
      "{'loss': 1.1361, 'learning_rate': 4.0000000000000003e-07, 'epoch': 29.76}\n",
      "{'loss': 1.1399, 'learning_rate': 1.3333333333333334e-07, 'epoch': 29.92}\n",
      "{'train_runtime': 449.361, 'train_samples_per_second': 667.615, 'train_steps_per_second': 41.726, 'train_loss': 1.3350471315511068, 'epoch': 30.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18750, training_loss=1.3350471315511068, metrics={'train_runtime': 449.361, 'train_samples_per_second': 667.615, 'train_steps_per_second': 41.726, 'train_loss': 1.3350471315511068, 'epoch': 30.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizerFast\n",
    "from datasets import Dataset\n",
    "from transformers import BartConfig, BartForConditionalGeneration\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq\n",
    "\n",
    "# 1. Generate arithmetic corpus\n",
    "corpus = [f\"{a} + {b} = {a + b}\" for a in range(100) for b in range(100)]\n",
    "\n",
    "# 2. Initialize and train tokenizer\n",
    "tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "tokenizer.pre_tokenizer = Whitespace()\n",
    "special_tokens = [\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
    "trainer = WordLevelTrainer(special_tokens=special_tokens)\n",
    "tokenizer.train_from_iterator(corpus, trainer)\n",
    "\n",
    "# 3. Add post-processing template for special tokens\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"[BOS] $A [EOS]\",\n",
    "    pair=\"[BOS] $A [EOS] $B:1 [EOS]:1\",\n",
    "    special_tokens=[\n",
    "        (\"[BOS]\", tokenizer.token_to_id(\"[BOS]\")),\n",
    "        (\"[EOS]\", tokenizer.token_to_id(\"[EOS]\"))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 4. Save and wrap in HuggingFace tokenizer\n",
    "tokenizer.save(\"arithmetic-tokenizer.json\")\n",
    "hf_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"arithmetic-tokenizer.json\",\n",
    "    bos_token=\"[BOS]\",\n",
    "    eos_token=\"[EOS]\",\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    ")\n",
    "hf_tokenizer.save_pretrained(\"custom-arithmetic-tokenizer\")\n",
    "\n",
    "# 5. Prepare dataset\n",
    "examples = [{\"input\": f\"{a} + {b}\", \"output\": str(a + b)} for a in range(100) for b in range(100)]\n",
    "dataset = Dataset.from_list(examples)\n",
    "\n",
    "# 6. Tokenize dataset\n",
    "def tokenize_function(example):\n",
    "    model_input = hf_tokenizer(example[\"input\"], padding=\"max_length\", truncation=True, max_length=16)\n",
    "    with hf_tokenizer.as_target_tokenizer():\n",
    "        labels = hf_tokenizer(example[\"output\"], padding=\"max_length\", truncation=True, max_length=4)\n",
    "    model_input[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_input\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n",
    "\n",
    "# 7. Define small BART config\n",
    "config = BartConfig(\n",
    "    vocab_size=hf_tokenizer.vocab_size,\n",
    "    d_model=64,\n",
    "    encoder_layers=1,\n",
    "    decoder_layers=1,\n",
    "    encoder_attention_heads=1,\n",
    "    decoder_attention_heads=1,\n",
    "    decoder_ffn_dim=32,\n",
    "    encoder_ffn_dim=32,\n",
    "    max_position_embeddings=64,\n",
    "    bos_token_id=hf_tokenizer.bos_token_id,\n",
    "    eos_token_id=hf_tokenizer.eos_token_id,\n",
    "    pad_token_id=hf_tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# 8. Initialize BART model\n",
    "model = BartForConditionalGeneration(config)\n",
    "\n",
    "# 9. Training setup\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=hf_tokenizer, model=model)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bart_addition\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    save_total_limit=1,\n",
    "    logging_steps=100,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=hf_tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# 10. Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "122db483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  2,  93,   4,  98,   3],\n",
      "        [  2,  60,   4,  72,   3],\n",
      "        [  2,   6,   4, 104,   3],\n",
      "        [  2, 105,   4, 105,   3],\n",
      "        [  2, 129,   4,   1,   3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]])}\n",
      "tensor([[  2,   2, 156,   3],\n",
      "        [  2,   2,   8,   3],\n",
      "        [  2,   2,   8,   3],\n",
      "        [  2,   2, 155,   3],\n",
      "        [  2,   2, 156,   3]])\n",
      "12 + 7 = 150\n",
      "45 + 33 = 97\n",
      "99 + 1 = 97\n",
      "0 + 0 = 149\n",
      "123 + 456 = 150\n"
     ]
    }
   ],
   "source": [
    "# 11. Inference\n",
    "test_inputs = [\"12 + 7\", \"45 + 33\", \"99 + 1\", \"0 + 0\", \"123 + 456\"]\n",
    "inputs = hf_tokenizer(test_inputs, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Generate predictions without token_type_ids\n",
    "output_ids = model.generate(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=8)  \n",
    "\n",
    "# Decode predictions\n",
    "predictions = hf_tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "print(inputs)\n",
    "print(output_ids)\n",
    "# 12. Print results\n",
    "for inp, pred in zip(test_inputs, predictions):\n",
    "    print(f\"{inp} = {pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa096b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS]\n"
     ]
    }
   ],
   "source": [
    "for k,i in hf_tokenizer.vocab.items():\n",
    "    if i == 2:\n",
    "        print(k)\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
