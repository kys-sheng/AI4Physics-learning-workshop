
Model parameters: 16,856,320
Model parameters: 7,839,872
Sample Data:
Sample 1: Input: '46 + 97 = ?', Target: '143'
Sample 2: Input: '40 + 66 = ?', Target: '106'
Sample 3: Input: '71 + 59 = ?', Target: '130'
Verifying tokenized data:
Input_ids sample: [0, 3761, 2055, 8783, 5457, 17487, 2, 1, 1, 1]
Labels sample: [0, 26332, 2, -100, -100, -100, -100, -100]
/var/folders/qz/5z66z7dj2pd54wr1ww93tbfc0000gn/T/ipykernel_67430/3633416086.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].
Training completed!